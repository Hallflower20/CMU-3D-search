{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, regularizers, callbacks, backend\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout, Add, LSTM, Embedding\n",
    "from tensorflow.keras.initializers import glorot_normal, glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Flatten, Dense, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_flux_desi = np.load(\"../DESI_spectra/galaxy_flux.npy\")\n",
    "snia_flux_desi = np.load(\"../DESI_spectra/snia_flux.npy\")\n",
    "snib_flux_desi = np.load(\"../DESI_spectra/snib_flux.npy\")\n",
    "snibc_flux_desi = np.load(\"../DESI_spectra/snibc_flux.npy\")\n",
    "snic_flux_desi = np.load(\"../DESI_spectra/snic_flux.npy\")\n",
    "sniin_flux_desi = np.load(\"../DESI_spectra/sniin_flux.npy\")\n",
    "sniilp_flux_desi = np.load(\"../DESI_spectra/sniilp_flux.npy\")\n",
    "sniip_flux_desi = np.load(\"../DESI_spectra/sniip_flux.npy\")\n",
    "kn_flux = np.load(\"../DESI_spectra/kn_flux.npy\")\n",
    "\n",
    "tde_flux_ztf = np.load(\"../ztf_spectra/tde_flux.npy\")\n",
    "tde_flux_paper = np.load(\"../tde_flux_1.npy\")\n",
    "snia_flux_ztf = np.load(\"../ztf_spectra/snia_flux.npy\")\n",
    "snii_flux_ztf = np.load(\"../ztf_spectra/snii_flux.npy\")\n",
    "snib_flux_ztf = np.load(\"../ztf_spectra/snib_flux.npy\")\n",
    "snic_flux_ztf = np.load(\"../ztf_spectra/snic_flux.npy\")\n",
    "galaxy_flux_ztf = np.load(\"../ztf_spectra/gal_flux.npy\")\n",
    "agn_flux = np.load(\"../ztf_spectra/agn_flux.npy\")\n",
    "nls_flux = np.load(\"../ztf_spectra/nls_flux.npy\")\n",
    "qso_flux = np.load(\"../ztf_spectra/qso_flux.npy\")\n",
    "\n",
    "snia_flux = np.vstack([snia_flux_desi, snia_flux_ztf])\n",
    "snibc_flux = np.vstack([snib_flux_desi, snib_flux_ztf, snibc_flux_desi, snic_flux_ztf, snic_flux_desi])\n",
    "snii_flux = np.vstack([sniin_flux_desi, snii_flux_ztf, sniin_flux_desi, sniilp_flux_desi, sniip_flux_desi])\n",
    "galaxy_flux = np.vstack([galaxy_flux_desi, galaxy_flux_ztf, agn_flux, nls_flux, qso_flux])\n",
    "tde_flux = np.vstack([tde_flux_ztf, tde_flux_paper])\n",
    "\n",
    "minw, maxw, nbins = 3000., 8000., 150\n",
    "\n",
    "ngalaxy, nbins  = galaxy_flux.shape\n",
    "nsnia, nbins  = snia_flux.shape\n",
    "nsnibc, nbins = snibc_flux.shape\n",
    "nsnii, nbins = snii_flux.shape\n",
    "ntde, nbins = tde_flux.shape\n",
    "nkn, nbins = kn_flux.shape\n",
    "ngalaxy, nsnia, nsnibc, nsnii, ntde, nkn, nbins\n",
    "\n",
    "x = np.concatenate([galaxy_flux, \n",
    "                    snia_flux,\n",
    "                    snibc_flux,\n",
    "                    snii_flux,\n",
    "                    tde_flux,\n",
    "                    kn_flux\n",
    "                   ]).reshape(-1, nbins, 1)\n",
    "\n",
    "labels = ['Galaxy',\n",
    "          'SN Ia',\n",
    "          'SN Ib/c',\n",
    "          'SN II',\n",
    "          'TDE',\n",
    "          'KN']\n",
    "ntypes = len(labels)\n",
    "\n",
    "# Convert y-label array to appropriate categorical array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(\n",
    "        np.concatenate([np.full(ngalaxy, 0), \n",
    "                        np.full(nsnia, 1),\n",
    "                        np.full(nsnibc, 2),\n",
    "                        np.full(nsnii, 3),\n",
    "                        np.full(ntde, 4),\n",
    "                        np.full(nkn, 5)\n",
    "                       ]))\n",
    "\n",
    "n_sample = [ngalaxy, nsnia, nsnibc, nsnii, ntde, nkn]\n",
    "weights = np.max(n_sample) / n_sample\n",
    "class_weight = {}\n",
    "for i in range(len(weights)):\n",
    "    class_weight[i] = weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "batch = 30\n",
    "epoch = 180\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "\n",
    "# Prepare for tracking results\n",
    "fold_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(x, y):\n",
    "    print(f\"Verifying fold {fold_no}...\")\n",
    "    \n",
    "    dropout = 0.6\n",
    "    model = tf.keras.models.load_model('kfold_model/fold_{fold_no}_b{batch}_e{epoch}_model.keras')\n",
    "\n",
    "    # Split the data into train and test for this fold\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "\n",
    "    all_fpr = None\n",
    "    all_tpr = None\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    pre = dict()\n",
    "    rec = dict()\n",
    "    for i in range(ntypes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])        \n",
    "        roc_auc = auc(fpr[i], tpr[i])\n",
    "\n",
    "        ax = axes[0]\n",
    "        ax.plot(fpr[i], tpr[i], label='{}; AUC = {:.2f}'.format(labels[i], roc_auc))\n",
    "        ax.grid(ls=':')\n",
    "\n",
    "        pre[i], rec[i], _ = precision_recall_curve(y_test[:,i], y_pred[:,i])\n",
    "\n",
    "        ax = axes[1]\n",
    "        ax.plot(rec[i], pre[i])\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(ntypes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(ntypes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    fpr['macro'] = all_fpr\n",
    "    tpr['macro'] = mean_tpr / ntypes\n",
    "    fpr['macro'] = np.insert(fpr['macro'], 0, 0)\n",
    "    tpr['macro'] = np.insert(tpr['macro'], 0, 0)\n",
    "    roc_auc_macro = auc(fpr['macro'], tpr['macro'])\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(fpr['macro'], tpr['macro'], lw=3, ls='--', color='k',\n",
    "            label='cat. avg. ROC\\nAUC = {:.2f}'.format(roc_auc_macro))\n",
    "    ax.set(xlim=(-0.01,1.01), xlabel='FPR = FP / (FP + TN)',\n",
    "           ylim=(-0.01,1.01), ylabel='recall (TPR) = TP / (TP + FN)',\n",
    "           title='ROC: AUC = {:.3f}'.format(roc_auc_macro),\n",
    "           aspect='equal')\n",
    "    ax.legend(fontsize=10, loc='lower right')\n",
    "\n",
    "    ax = axes[1]\n",
    "    pre['micro'], rec['micro'], _ = precision_recall_curve(y_test.ravel(), y_pred.ravel())\n",
    "    ax.plot(rec['micro'], pre['micro'], lw=3, ls='--', color='k')\n",
    "\n",
    "    f_scores = np.linspace(0.1, 0.9, num=5)\n",
    "    for f_score in f_scores:\n",
    "        x_ = np.linspace(0.01, 1)\n",
    "        y_ = f_score * x_ / (2 * x_ - f_score)\n",
    "        l, = plt.plot(x_[y_ >= 0], y_[y_ >= 0], color='k', ls='--', alpha=0.3)\n",
    "        ax.annotate(' $F_{{1}}={0:0.1f}$'.format(f_score), xy=(1.01, y_[45]-0.02),\n",
    "                    fontsize=12, alpha=0.8)\n",
    "    ax.grid(ls=':')\n",
    "    ax.set(xlabel='recall (TPR) = TP / (TP + FN)',\n",
    "           ylabel='precision = TP / (TP + FP)',\n",
    "           title='Average precision = {:.3f}'.format(average_precision_score(y_test, y_pred)),\n",
    "           aspect='equal')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('fold{}_b{}_e{}_metrics.png'.format(fold, batch, epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
