{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0158d44d-f162-4785-bb2f-5bc0cb8a2429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:27:32.404637: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-27 16:27:32.404664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-27 16:27:32.474013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 16:27:32.616844: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 16:27:37.502755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, regularizers, callbacks, backend\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout, Add, LSTM, Embedding\n",
    "from tensorflow.keras.initializers import glorot_normal, glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mpl.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86433abb-b561-43bc-8da6-cf74c63b6746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Flatten, Dense, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fdee7f-a16f-4896-9f85-441fa9a21627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def network_new(input_shape, ncat, learning_rate=0.00021544346900318823, reg=0.0032, dropout=0.1, seed=1):\n",
    "    \"\"\"Define the CNN structure with improvements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : int\n",
    "        Shape of the input spectra.\n",
    "    ncat : int\n",
    "        Number of categories.\n",
    "    learning_rate : float\n",
    "        Learning rate.\n",
    "    reg : float\n",
    "        Regularization factor.\n",
    "    dropout : float\n",
    "        Dropout rate.\n",
    "    seed : int\n",
    "        Seed of initializer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.keras.Model\n",
    "        A model instance of the network.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "    initializer = HeNormal(seed=seed)\n",
    "\n",
    "    def conv_block(X, filters, kernel_size=5, reg=0.0032):\n",
    "        # Shortcut (residual connection) path\n",
    "        X_shortcut = X\n",
    "\n",
    "        # Main path\n",
    "        X = Conv1D(filters=filters, kernel_size=kernel_size, strides=1, padding='same',\n",
    "                   kernel_regularizer=l1(reg),\n",
    "                   kernel_initializer=initializer)(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(pool_size=2)(X)\n",
    "\n",
    "        # Adjust the shortcut path to match the dimensions of the main path\n",
    "        X_shortcut = Conv1D(filters, kernel_size=1, padding='same')(X_shortcut)\n",
    "        X_shortcut = MaxPooling1D(pool_size=2)(X_shortcut)  # Add pooling to the shortcut as well\n",
    "\n",
    "        # Add the main path and shortcut\n",
    "        X = Add()([X, X_shortcut])\n",
    "        return X\n",
    "\n",
    "    # Convolutional layers with residual connections\n",
    "    X = conv_block(X_input, filters=16)\n",
    "    X = conv_block(X, filters=32)\n",
    "    X = conv_block(X, filters=64)\n",
    "    X = conv_block(X, filters=128)\n",
    "\n",
    "    # Flatten to fully connected dense layer.\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512, kernel_regularizer=l2(reg), activation='relu')(X)\n",
    "    X = Dropout(rate=dropout)(X)\n",
    "    X = Dense(256, kernel_regularizer=l2(reg), activation='relu')(X)\n",
    "    X = Dropout(rate=dropout)(X)\n",
    "    \n",
    "    # Output layer with softmax activation.\n",
    "    X = Dense(ncat, kernel_regularizer=l2(reg), activation='softmax', name='Output_Classes')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='Enhanced_SNnet')\n",
    "    \n",
    "    # Set up optimizer with learning rate scheduler\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15392fb-b1af-4e7a-90d9-5ae07ee4445f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "galaxy_flux_desi = np.load(\"DESI_spectra/galaxy_flux.npy\")\n",
    "snia_flux_desi = np.load(\"DESI_spectra/snia_flux.npy\")\n",
    "snib_flux_desi = np.load(\"DESI_spectra/snib_flux.npy\")\n",
    "snibc_flux_desi = np.load(\"DESI_spectra/snibc_flux.npy\")\n",
    "snic_flux_desi = np.load(\"DESI_spectra/snic_flux.npy\")\n",
    "sniin_flux_desi = np.load(\"DESI_spectra/sniin_flux.npy\")\n",
    "sniilp_flux_desi = np.load(\"DESI_spectra/sniilp_flux.npy\")\n",
    "sniip_flux_desi = np.load(\"DESI_spectra/sniip_flux.npy\")\n",
    "kn_flux = np.load(\"DESI_spectra/kn_flux.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20b27c4-9efb-40a5-ba4f-b19eb468ef8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tde_flux_ztf = np.load(\"ztf_spectra/tde_flux.npy\")\n",
    "tde_flux_paper = np.load(\"tde_flux_1.npy\")\n",
    "snia_flux_ztf = np.load(\"ztf_spectra/snia_flux.npy\")\n",
    "snii_flux_ztf = np.load(\"ztf_spectra/snii_flux.npy\")\n",
    "snib_flux_ztf = np.load(\"ztf_spectra/snib_flux.npy\")\n",
    "snic_flux_ztf = np.load(\"ztf_spectra/snic_flux.npy\")\n",
    "galaxy_flux_ztf = np.load(\"ztf_spectra/gal_flux.npy\")\n",
    "agn_flux = np.load(\"ztf_spectra/agn_flux.npy\")\n",
    "nls_flux = np.load(\"ztf_spectra/nls_flux.npy\")\n",
    "qso_flux = np.load(\"ztf_spectra/qso_flux.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08b8856-8a79-48e2-898a-dff40f7c731b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snia_flux = np.vstack([snia_flux_desi, snia_flux_ztf])\n",
    "snibc_flux = np.vstack([snib_flux_desi, snib_flux_ztf, snibc_flux_desi, snic_flux_ztf, snic_flux_desi])\n",
    "snii_flux = np.vstack([sniin_flux_desi, snii_flux_ztf, sniin_flux_desi, sniilp_flux_desi, sniip_flux_desi])\n",
    "galaxy_flux = np.vstack([galaxy_flux_desi, galaxy_flux_ztf, agn_flux, nls_flux, qso_flux])\n",
    "tde_flux = np.vstack([tde_flux_ztf, tde_flux_paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73a8d30-5a75-49ce-a3c2-0f5b393de941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minw, maxw, nbins = 3000., 8000., 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e488ce1d-64c1-49d0-b188-b0d18d1fb5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10169, 14370, 29787, 42604, 224, 8947, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngalaxy, nbins  = galaxy_flux.shape\n",
    "nsnia, nbins  = snia_flux.shape\n",
    "nsnibc, nbins = snibc_flux.shape\n",
    "nsnii, nbins = snii_flux.shape\n",
    "ntde, nbins = tde_flux.shape\n",
    "nkn, nbins = kn_flux.shape\n",
    "ngalaxy, nsnia, nsnibc, nsnii, ntde, nkn, nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d6c0b3-9db1-4082-ae58-c9826f8ef668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.concatenate([galaxy_flux, \n",
    "                    snia_flux,\n",
    "                    snibc_flux,\n",
    "                    snii_flux,\n",
    "                    tde_flux,\n",
    "                    kn_flux\n",
    "                   ]).reshape(-1, nbins, 1)\n",
    "\n",
    "labels = ['Galaxy',\n",
    "          'SN Ia',\n",
    "          'SN Ib/c',\n",
    "          'SN II',\n",
    "          'TDE',\n",
    "          'KN']\n",
    "ntypes = len(labels)\n",
    "\n",
    "# Convert y-label array to appropriate categorical array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(\n",
    "        np.concatenate([np.full(ngalaxy, 0), \n",
    "                        np.full(nsnia, 1),\n",
    "                        np.full(nsnibc, 2),\n",
    "                        np.full(nsnii, 3),\n",
    "                        np.full(ntde, 4),\n",
    "                        np.full(nkn, 5)\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62499222-2c51-43aa-9622-e54dcba97375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.189595830465139,\n",
       " 1: 2.9647877522616564,\n",
       " 2: 1.430288380837278,\n",
       " 3: 1.0,\n",
       " 4: 190.19642857142858,\n",
       " 5: 4.761819604336649}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = [ngalaxy, nsnia, nsnibc, nsnii, ntde, nkn]\n",
    "weights = np.max(n_sample) / n_sample\n",
    "class_weight = {}\n",
    "for i in range(len(weights)):\n",
    "    class_weight[i] = weights[i]\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d2913c-bcbd-4424-b642-897218584c61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:28:03.439417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38379 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:28:06.230548: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8903\n",
      "2024-11-27 16:28:08.374626: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f487ddb92b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-27 16:28:08.374644: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-11-27 16:28:08.381858: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732753688.477480 1845797 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830/2830 [==============================] - ETA: 0s - loss: 16.6333 - accuracy: 0.3460\n",
      "Epoch 1: val_loss improved from inf to 11.51625, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 28s 7ms/step - loss: 16.6333 - accuracy: 0.3460 - val_loss: 11.5163 - val_accuracy: 0.4600 - lr: 2.1544e-04\n",
      "Epoch 2/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 11.0255 - accuracy: 0.4982\n",
      "Epoch 2: val_loss improved from 11.51625 to 7.78196, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 11.0254 - accuracy: 0.4982 - val_loss: 7.7820 - val_accuracy: 0.5937 - lr: 2.1544e-04\n",
      "Epoch 3/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 7.8177 - accuracy: 0.5786\n",
      "Epoch 3: val_loss improved from 7.78196 to 5.64854, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 7.8167 - accuracy: 0.5787 - val_loss: 5.6485 - val_accuracy: 0.6067 - lr: 2.1544e-04\n",
      "Epoch 4/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 6.0769 - accuracy: 0.6060\n",
      "Epoch 4: val_loss improved from 5.64854 to 4.49222, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 6.0769 - accuracy: 0.6060 - val_loss: 4.4922 - val_accuracy: 0.6645 - lr: 2.1544e-04\n",
      "Epoch 5/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 5.0407 - accuracy: 0.6272\n",
      "Epoch 5: val_loss improved from 4.49222 to 3.71977, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 5.0394 - accuracy: 0.6273 - val_loss: 3.7198 - val_accuracy: 0.6423 - lr: 2.1544e-04\n",
      "Epoch 6/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 4.4821 - accuracy: 0.6389\n",
      "Epoch 6: val_loss improved from 3.71977 to 3.11362, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 4.4823 - accuracy: 0.6389 - val_loss: 3.1136 - val_accuracy: 0.6896 - lr: 2.1544e-04\n",
      "Epoch 7/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 4.1708 - accuracy: 0.6441\n",
      "Epoch 7: val_loss improved from 3.11362 to 3.01622, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 4.1708 - accuracy: 0.6441 - val_loss: 3.0162 - val_accuracy: 0.6819 - lr: 2.1544e-04\n",
      "Epoch 8/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 3.9379 - accuracy: 0.6495\n",
      "Epoch 8: val_loss did not improve from 3.01622\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.9384 - accuracy: 0.6494 - val_loss: 3.4072 - val_accuracy: 0.6033 - lr: 2.1544e-04\n",
      "Epoch 9/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 3.8130 - accuracy: 0.6553\n",
      "Epoch 9: val_loss improved from 3.01622 to 2.61363, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.8130 - accuracy: 0.6553 - val_loss: 2.6136 - val_accuracy: 0.6808 - lr: 2.1544e-04\n",
      "Epoch 10/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 3.4672 - accuracy: 0.6661\n",
      "Epoch 10: val_loss did not improve from 2.61363\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.4675 - accuracy: 0.6659 - val_loss: 2.6473 - val_accuracy: 0.6494 - lr: 2.1544e-04\n",
      "Epoch 11/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 3.4451 - accuracy: 0.6633\n",
      "Epoch 11: val_loss did not improve from 2.61363\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.4464 - accuracy: 0.6633 - val_loss: 2.8870 - val_accuracy: 0.5873 - lr: 2.1544e-04\n",
      "Epoch 12/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 3.2054 - accuracy: 0.6755\n",
      "Epoch 12: val_loss improved from 2.61363 to 2.31222, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.2050 - accuracy: 0.6755 - val_loss: 2.3122 - val_accuracy: 0.7026 - lr: 2.1544e-04\n",
      "Epoch 13/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 3.2348 - accuracy: 0.6705\n",
      "Epoch 13: val_loss improved from 2.31222 to 2.13606, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.2346 - accuracy: 0.6705 - val_loss: 2.1361 - val_accuracy: 0.7140 - lr: 2.1544e-04\n",
      "Epoch 14/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 3.2380 - accuracy: 0.6695\n",
      "Epoch 14: val_loss did not improve from 2.13606\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.2375 - accuracy: 0.6694 - val_loss: 2.5094 - val_accuracy: 0.6362 - lr: 2.1544e-04\n",
      "Epoch 15/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 3.0546 - accuracy: 0.6763\n",
      "Epoch 15: val_loss did not improve from 2.13606\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0548 - accuracy: 0.6763 - val_loss: 2.2500 - val_accuracy: 0.7047 - lr: 2.1544e-04\n",
      "Epoch 16/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 2.9756 - accuracy: 0.6802\n",
      "Epoch 16: val_loss improved from 2.13606 to 2.11477, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 2.9755 - accuracy: 0.6802 - val_loss: 2.1148 - val_accuracy: 0.7236 - lr: 2.1544e-04\n",
      "Epoch 17/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 3.1105 - accuracy: 0.6719\n",
      "Epoch 17: val_loss did not improve from 2.11477\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.1105 - accuracy: 0.6719 - val_loss: 2.1809 - val_accuracy: 0.6813 - lr: 2.1544e-04\n",
      "Epoch 18/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 2.8838 - accuracy: 0.6856\n",
      "Epoch 18: val_loss improved from 2.11477 to 1.92509, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8836 - accuracy: 0.6856 - val_loss: 1.9251 - val_accuracy: 0.7029 - lr: 2.1544e-04\n",
      "Epoch 19/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 3.0509 - accuracy: 0.6741\n",
      "Epoch 19: val_loss did not improve from 1.92509\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0508 - accuracy: 0.6741 - val_loss: 2.0858 - val_accuracy: 0.7094 - lr: 2.1544e-04\n",
      "Epoch 20/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.7625 - accuracy: 0.6928\n",
      "Epoch 20: val_loss improved from 1.92509 to 1.74269, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7618 - accuracy: 0.6928 - val_loss: 1.7427 - val_accuracy: 0.7352 - lr: 2.1544e-04\n",
      "Epoch 21/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.9334 - accuracy: 0.6819\n",
      "Epoch 21: val_loss did not improve from 1.74269\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.9334 - accuracy: 0.6819 - val_loss: 2.1219 - val_accuracy: 0.6854 - lr: 2.1544e-04\n",
      "Epoch 22/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 2.8128 - accuracy: 0.6869\n",
      "Epoch 22: val_loss did not improve from 1.74269\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8131 - accuracy: 0.6868 - val_loss: 2.1745 - val_accuracy: 0.6737 - lr: 2.1544e-04\n",
      "Epoch 23/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.7650 - accuracy: 0.6878\n",
      "Epoch 23: val_loss did not improve from 1.74269\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7650 - accuracy: 0.6879 - val_loss: 2.2708 - val_accuracy: 0.6343 - lr: 2.1544e-04\n",
      "Epoch 24/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.8686 - accuracy: 0.6839\n",
      "Epoch 24: val_loss did not improve from 1.74269\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8686 - accuracy: 0.6839 - val_loss: 2.0078 - val_accuracy: 0.7021 - lr: 2.1544e-04\n",
      "Epoch 25/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.7091 - accuracy: 0.6916\n",
      "Epoch 25: val_loss did not improve from 1.74269\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010772173118311912.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7090 - accuracy: 0.6916 - val_loss: 1.9102 - val_accuracy: 0.7040 - lr: 2.1544e-04\n",
      "Epoch 26/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.3929 - accuracy: 0.7158\n",
      "Epoch 26: val_loss improved from 1.74269 to 1.66785, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 2.3930 - accuracy: 0.7158 - val_loss: 1.6679 - val_accuracy: 0.7367 - lr: 1.0772e-04\n",
      "Epoch 27/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.2552 - accuracy: 0.7239\n",
      "Epoch 27: val_loss did not improve from 1.66785\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.2550 - accuracy: 0.7240 - val_loss: 1.6700 - val_accuracy: 0.7225 - lr: 1.0772e-04\n",
      "Epoch 28/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.2301 - accuracy: 0.7262\n",
      "Epoch 28: val_loss did not improve from 1.66785\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.2305 - accuracy: 0.7262 - val_loss: 1.6888 - val_accuracy: 0.7149 - lr: 1.0772e-04\n",
      "Epoch 29/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 2.1927 - accuracy: 0.7293\n",
      "Epoch 29: val_loss improved from 1.66785 to 1.50749, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1918 - accuracy: 0.7295 - val_loss: 1.5075 - val_accuracy: 0.7373 - lr: 1.0772e-04\n",
      "Epoch 30/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.1508 - accuracy: 0.7339\n",
      "Epoch 30: val_loss did not improve from 1.50749\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1508 - accuracy: 0.7339 - val_loss: 1.5295 - val_accuracy: 0.7346 - lr: 1.0772e-04\n",
      "Epoch 31/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 2.1114 - accuracy: 0.7331\n",
      "Epoch 31: val_loss did not improve from 1.50749\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1115 - accuracy: 0.7331 - val_loss: 1.5180 - val_accuracy: 0.7437 - lr: 1.0772e-04\n",
      "Epoch 32/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.1420 - accuracy: 0.7328\n",
      "Epoch 32: val_loss did not improve from 1.50749\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1420 - accuracy: 0.7328 - val_loss: 1.5147 - val_accuracy: 0.7269 - lr: 1.0772e-04\n",
      "Epoch 33/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 2.1004 - accuracy: 0.7360\n",
      "Epoch 33: val_loss did not improve from 1.50749\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1008 - accuracy: 0.7360 - val_loss: 1.6996 - val_accuracy: 0.7125 - lr: 1.0772e-04\n",
      "Epoch 34/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.1771 - accuracy: 0.7324\n",
      "Epoch 34: val_loss did not improve from 1.50749\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 5.386086559155956e-05.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1770 - accuracy: 0.7324 - val_loss: 1.5218 - val_accuracy: 0.7313 - lr: 1.0772e-04\n",
      "Epoch 35/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.9227 - accuracy: 0.7540\n",
      "Epoch 35: val_loss improved from 1.50749 to 1.37400, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.9225 - accuracy: 0.7540 - val_loss: 1.3740 - val_accuracy: 0.7439 - lr: 5.3861e-05\n",
      "Epoch 36/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.8232 - accuracy: 0.7629\n",
      "Epoch 36: val_loss improved from 1.37400 to 1.30758, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.8232 - accuracy: 0.7629 - val_loss: 1.3076 - val_accuracy: 0.7630 - lr: 5.3861e-05\n",
      "Epoch 37/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.8490 - accuracy: 0.7613\n",
      "Epoch 37: val_loss did not improve from 1.30758\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.8489 - accuracy: 0.7614 - val_loss: 1.3776 - val_accuracy: 0.7462 - lr: 5.3861e-05\n",
      "Epoch 38/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.7723 - accuracy: 0.7684\n",
      "Epoch 38: val_loss did not improve from 1.30758\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7723 - accuracy: 0.7684 - val_loss: 1.3145 - val_accuracy: 0.7546 - lr: 5.3861e-05\n",
      "Epoch 39/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.7721 - accuracy: 0.7690\n",
      "Epoch 39: val_loss did not improve from 1.30758\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7721 - accuracy: 0.7690 - val_loss: 1.3201 - val_accuracy: 0.7527 - lr: 5.3861e-05\n",
      "Epoch 40/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.7503 - accuracy: 0.7720\n",
      "Epoch 40: val_loss did not improve from 1.30758\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7506 - accuracy: 0.7720 - val_loss: 1.3201 - val_accuracy: 0.7500 - lr: 5.3861e-05\n",
      "Epoch 41/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.7479 - accuracy: 0.7722\n",
      "Epoch 41: val_loss did not improve from 1.30758\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 2.693043279577978e-05.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7478 - accuracy: 0.7722 - val_loss: 1.3467 - val_accuracy: 0.7421 - lr: 5.3861e-05\n",
      "Epoch 42/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.6564 - accuracy: 0.7830\n",
      "Epoch 42: val_loss improved from 1.30758 to 1.25184, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.6562 - accuracy: 0.7830 - val_loss: 1.2518 - val_accuracy: 0.7625 - lr: 2.6930e-05\n",
      "Epoch 43/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.5903 - accuracy: 0.7880\n",
      "Epoch 43: val_loss improved from 1.25184 to 1.21256, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.5903 - accuracy: 0.7880 - val_loss: 1.2126 - val_accuracy: 0.7688 - lr: 2.6930e-05\n",
      "Epoch 44/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.5813 - accuracy: 0.7906\n",
      "Epoch 44: val_loss did not improve from 1.21256\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.5817 - accuracy: 0.7905 - val_loss: 1.2315 - val_accuracy: 0.7569 - lr: 2.6930e-05\n",
      "Epoch 45/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.5549 - accuracy: 0.7943\n",
      "Epoch 45: val_loss improved from 1.21256 to 1.18793, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.5549 - accuracy: 0.7943 - val_loss: 1.1879 - val_accuracy: 0.7703 - lr: 2.6930e-05\n",
      "Epoch 46/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.5494 - accuracy: 0.7958\n",
      "Epoch 46: val_loss did not improve from 1.18793\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.5496 - accuracy: 0.7958 - val_loss: 1.2057 - val_accuracy: 0.7648 - lr: 2.6930e-05\n",
      "Epoch 47/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.5316 - accuracy: 0.7974\n",
      "Epoch 47: val_loss did not improve from 1.18793\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.5315 - accuracy: 0.7975 - val_loss: 1.1948 - val_accuracy: 0.7656 - lr: 2.6930e-05\n",
      "Epoch 48/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.5057 - accuracy: 0.8013\n",
      "Epoch 48: val_loss improved from 1.18793 to 1.18516, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.5057 - accuracy: 0.8013 - val_loss: 1.1852 - val_accuracy: 0.7678 - lr: 2.6930e-05\n",
      "Epoch 49/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.5006 - accuracy: 0.8007\n",
      "Epoch 49: val_loss improved from 1.18516 to 1.16933, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.5005 - accuracy: 0.8007 - val_loss: 1.1693 - val_accuracy: 0.7729 - lr: 2.6930e-05\n",
      "Epoch 50/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.4983 - accuracy: 0.8032\n",
      "Epoch 50: val_loss did not improve from 1.16933\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4983 - accuracy: 0.8032 - val_loss: 1.1874 - val_accuracy: 0.7668 - lr: 2.6930e-05\n",
      "Epoch 51/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.4803 - accuracy: 0.8036\n",
      "Epoch 51: val_loss improved from 1.16933 to 1.16349, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4803 - accuracy: 0.8036 - val_loss: 1.1635 - val_accuracy: 0.7742 - lr: 2.6930e-05\n",
      "Epoch 52/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.4847 - accuracy: 0.8065\n",
      "Epoch 52: val_loss did not improve from 1.16349\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4845 - accuracy: 0.8066 - val_loss: 1.1889 - val_accuracy: 0.7696 - lr: 2.6930e-05\n",
      "Epoch 53/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.4590 - accuracy: 0.8081\n",
      "Epoch 53: val_loss improved from 1.16349 to 1.16218, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.4589 - accuracy: 0.8081 - val_loss: 1.1622 - val_accuracy: 0.7735 - lr: 2.6930e-05\n",
      "Epoch 54/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.4677 - accuracy: 0.8075\n",
      "Epoch 54: val_loss did not improve from 1.16218\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4677 - accuracy: 0.8075 - val_loss: 1.1868 - val_accuracy: 0.7710 - lr: 2.6930e-05\n",
      "Epoch 55/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.4520 - accuracy: 0.8112\n",
      "Epoch 55: val_loss did not improve from 1.16218\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4520 - accuracy: 0.8112 - val_loss: 1.1936 - val_accuracy: 0.7631 - lr: 2.6930e-05\n",
      "Epoch 56/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.4346 - accuracy: 0.8138\n",
      "Epoch 56: val_loss did not improve from 1.16218\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4350 - accuracy: 0.8137 - val_loss: 1.1837 - val_accuracy: 0.7696 - lr: 2.6930e-05\n",
      "Epoch 57/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.4294 - accuracy: 0.8143\n",
      "Epoch 57: val_loss did not improve from 1.16218\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4294 - accuracy: 0.8143 - val_loss: 1.1829 - val_accuracy: 0.7663 - lr: 2.6930e-05\n",
      "Epoch 58/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.4200 - accuracy: 0.8162\n",
      "Epoch 58: val_loss did not improve from 1.16218\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.346521639788989e-05.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4197 - accuracy: 0.8162 - val_loss: 1.2048 - val_accuracy: 0.7621 - lr: 2.6930e-05\n",
      "Epoch 59/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.3675 - accuracy: 0.8247\n",
      "Epoch 59: val_loss did not improve from 1.16218\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3679 - accuracy: 0.8246 - val_loss: 1.1727 - val_accuracy: 0.7677 - lr: 1.3465e-05\n",
      "Epoch 60/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.3451 - accuracy: 0.8281\n",
      "Epoch 60: val_loss did not improve from 1.16218\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3450 - accuracy: 0.8281 - val_loss: 1.1659 - val_accuracy: 0.7715 - lr: 1.3465e-05\n",
      "Epoch 61/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.3335 - accuracy: 0.8285\n",
      "Epoch 61: val_loss improved from 1.16218 to 1.13947, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3335 - accuracy: 0.8286 - val_loss: 1.1395 - val_accuracy: 0.7806 - lr: 1.3465e-05\n",
      "Epoch 62/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.3215 - accuracy: 0.8304\n",
      "Epoch 62: val_loss did not improve from 1.13947\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3214 - accuracy: 0.8304 - val_loss: 1.1452 - val_accuracy: 0.7748 - lr: 1.3465e-05\n",
      "Epoch 63/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.3199 - accuracy: 0.8305\n",
      "Epoch 63: val_loss did not improve from 1.13947\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3200 - accuracy: 0.8304 - val_loss: 1.1556 - val_accuracy: 0.7725 - lr: 1.3465e-05\n",
      "Epoch 64/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.3121 - accuracy: 0.8336\n",
      "Epoch 64: val_loss did not improve from 1.13947\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3121 - accuracy: 0.8336 - val_loss: 1.1409 - val_accuracy: 0.7805 - lr: 1.3465e-05\n",
      "Epoch 65/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.3047 - accuracy: 0.8349\n",
      "Epoch 65: val_loss did not improve from 1.13947\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3049 - accuracy: 0.8348 - val_loss: 1.1423 - val_accuracy: 0.7780 - lr: 1.3465e-05\n",
      "Epoch 66/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.3045 - accuracy: 0.8351\n",
      "Epoch 66: val_loss did not improve from 1.13947\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.732608198944945e-06.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3047 - accuracy: 0.8351 - val_loss: 1.1655 - val_accuracy: 0.7736 - lr: 1.3465e-05\n",
      "Epoch 67/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.2787 - accuracy: 0.8401\n",
      "Epoch 67: val_loss improved from 1.13947 to 1.13777, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2791 - accuracy: 0.8400 - val_loss: 1.1378 - val_accuracy: 0.7795 - lr: 6.7326e-06\n",
      "Epoch 68/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.2611 - accuracy: 0.8417\n",
      "Epoch 68: val_loss improved from 1.13777 to 1.13181, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2608 - accuracy: 0.8417 - val_loss: 1.1318 - val_accuracy: 0.7805 - lr: 6.7326e-06\n",
      "Epoch 69/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.2507 - accuracy: 0.8437\n",
      "Epoch 69: val_loss did not improve from 1.13181\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2508 - accuracy: 0.8437 - val_loss: 1.1324 - val_accuracy: 0.7798 - lr: 6.7326e-06\n",
      "Epoch 70/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.2459 - accuracy: 0.8439\n",
      "Epoch 70: val_loss improved from 1.13181 to 1.13114, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2454 - accuracy: 0.8441 - val_loss: 1.1311 - val_accuracy: 0.7805 - lr: 6.7326e-06\n",
      "Epoch 71/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.2470 - accuracy: 0.8436\n",
      "Epoch 71: val_loss did not improve from 1.13114\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2473 - accuracy: 0.8435 - val_loss: 1.1351 - val_accuracy: 0.7793 - lr: 6.7326e-06\n",
      "Epoch 72/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.2453 - accuracy: 0.8435\n",
      "Epoch 72: val_loss did not improve from 1.13114\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2452 - accuracy: 0.8436 - val_loss: 1.1357 - val_accuracy: 0.7773 - lr: 6.7326e-06\n",
      "Epoch 73/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.2306 - accuracy: 0.8470\n",
      "Epoch 73: val_loss did not improve from 1.13114\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2305 - accuracy: 0.8470 - val_loss: 1.1371 - val_accuracy: 0.7792 - lr: 6.7326e-06\n",
      "Epoch 74/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.2339 - accuracy: 0.8464\n",
      "Epoch 74: val_loss improved from 1.13114 to 1.12641, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2339 - accuracy: 0.8464 - val_loss: 1.1264 - val_accuracy: 0.7829 - lr: 6.7326e-06\n",
      "Epoch 75/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.2271 - accuracy: 0.8476\n",
      "Epoch 75: val_loss did not improve from 1.12641\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2269 - accuracy: 0.8477 - val_loss: 1.1413 - val_accuracy: 0.7780 - lr: 6.7326e-06\n",
      "Epoch 76/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.2274 - accuracy: 0.8487\n",
      "Epoch 76: val_loss did not improve from 1.12641\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2274 - accuracy: 0.8487 - val_loss: 1.1319 - val_accuracy: 0.7802 - lr: 6.7326e-06\n",
      "Epoch 77/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.2197 - accuracy: 0.8493\n",
      "Epoch 77: val_loss did not improve from 1.12641\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2194 - accuracy: 0.8494 - val_loss: 1.1318 - val_accuracy: 0.7821 - lr: 6.7326e-06\n",
      "Epoch 78/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.2151 - accuracy: 0.8503\n",
      "Epoch 78: val_loss did not improve from 1.12641\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2150 - accuracy: 0.8503 - val_loss: 1.1336 - val_accuracy: 0.7813 - lr: 6.7326e-06\n",
      "Epoch 79/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.2124 - accuracy: 0.8500\n",
      "Epoch 79: val_loss did not improve from 1.12641\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.3663040994724724e-06.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2126 - accuracy: 0.8500 - val_loss: 1.1313 - val_accuracy: 0.7808 - lr: 6.7326e-06\n",
      "Epoch 80/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1972 - accuracy: 0.8538\n",
      "Epoch 80: val_loss did not improve from 1.12641\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1977 - accuracy: 0.8536 - val_loss: 1.1275 - val_accuracy: 0.7809 - lr: 3.3663e-06\n",
      "Epoch 81/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1946 - accuracy: 0.8537\n",
      "Epoch 81: val_loss improved from 1.12641 to 1.12634, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1948 - accuracy: 0.8537 - val_loss: 1.1263 - val_accuracy: 0.7825 - lr: 3.3663e-06\n",
      "Epoch 82/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1924 - accuracy: 0.8549\n",
      "Epoch 82: val_loss did not improve from 1.12634\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1924 - accuracy: 0.8549 - val_loss: 1.1286 - val_accuracy: 0.7802 - lr: 3.3663e-06\n",
      "Epoch 83/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1906 - accuracy: 0.8548\n",
      "Epoch 83: val_loss did not improve from 1.12634\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1909 - accuracy: 0.8548 - val_loss: 1.1285 - val_accuracy: 0.7817 - lr: 3.3663e-06\n",
      "Epoch 84/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1898 - accuracy: 0.8540\n",
      "Epoch 84: val_loss improved from 1.12634 to 1.12569, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1898 - accuracy: 0.8540 - val_loss: 1.1257 - val_accuracy: 0.7822 - lr: 3.3663e-06\n",
      "Epoch 85/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1866 - accuracy: 0.8561\n",
      "Epoch 85: val_loss did not improve from 1.12569\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1865 - accuracy: 0.8561 - val_loss: 1.1289 - val_accuracy: 0.7824 - lr: 3.3663e-06\n",
      "Epoch 86/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1891 - accuracy: 0.8548\n",
      "Epoch 86: val_loss did not improve from 1.12569\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1886 - accuracy: 0.8549 - val_loss: 1.1266 - val_accuracy: 0.7828 - lr: 3.3663e-06\n",
      "Epoch 87/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.1786 - accuracy: 0.8562\n",
      "Epoch 87: val_loss did not improve from 1.12569\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1786 - accuracy: 0.8561 - val_loss: 1.1315 - val_accuracy: 0.7813 - lr: 3.3663e-06\n",
      "Epoch 88/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1769 - accuracy: 0.8563\n",
      "Epoch 88: val_loss did not improve from 1.12569\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1770 - accuracy: 0.8562 - val_loss: 1.1292 - val_accuracy: 0.7813 - lr: 3.3663e-06\n",
      "Epoch 89/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1802 - accuracy: 0.8565\n",
      "Epoch 89: val_loss did not improve from 1.12569\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.6831520497362362e-06.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1800 - accuracy: 0.8564 - val_loss: 1.1322 - val_accuracy: 0.7805 - lr: 3.3663e-06\n",
      "Epoch 90/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1679 - accuracy: 0.8584\n",
      "Epoch 90: val_loss did not improve from 1.12569\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1680 - accuracy: 0.8584 - val_loss: 1.1263 - val_accuracy: 0.7823 - lr: 1.6832e-06\n",
      "Epoch 91/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1606 - accuracy: 0.8603\n",
      "Epoch 91: val_loss improved from 1.12569 to 1.12214, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1606 - accuracy: 0.8603 - val_loss: 1.1221 - val_accuracy: 0.7830 - lr: 1.6832e-06\n",
      "Epoch 92/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1648 - accuracy: 0.8594\n",
      "Epoch 92: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1647 - accuracy: 0.8594 - val_loss: 1.1231 - val_accuracy: 0.7831 - lr: 1.6832e-06\n",
      "Epoch 93/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1630 - accuracy: 0.8590\n",
      "Epoch 93: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1631 - accuracy: 0.8590 - val_loss: 1.1270 - val_accuracy: 0.7813 - lr: 1.6832e-06\n",
      "Epoch 94/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1626 - accuracy: 0.8600\n",
      "Epoch 94: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1625 - accuracy: 0.8600 - val_loss: 1.1294 - val_accuracy: 0.7812 - lr: 1.6832e-06\n",
      "Epoch 95/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1582 - accuracy: 0.8602\n",
      "Epoch 95: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1583 - accuracy: 0.8601 - val_loss: 1.1251 - val_accuracy: 0.7813 - lr: 1.6832e-06\n",
      "Epoch 96/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1594 - accuracy: 0.8601\n",
      "Epoch 96: val_loss did not improve from 1.12214\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 8.415760248681181e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1596 - accuracy: 0.8600 - val_loss: 1.1247 - val_accuracy: 0.7823 - lr: 1.6832e-06\n",
      "Epoch 97/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1540 - accuracy: 0.8616\n",
      "Epoch 97: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1539 - accuracy: 0.8616 - val_loss: 1.1234 - val_accuracy: 0.7827 - lr: 8.4158e-07\n",
      "Epoch 98/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1534 - accuracy: 0.8611\n",
      "Epoch 98: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1535 - accuracy: 0.8611 - val_loss: 1.1252 - val_accuracy: 0.7824 - lr: 8.4158e-07\n",
      "Epoch 99/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1534 - accuracy: 0.8611\n",
      "Epoch 99: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1534 - accuracy: 0.8610 - val_loss: 1.1259 - val_accuracy: 0.7818 - lr: 8.4158e-07\n",
      "Epoch 100/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1524 - accuracy: 0.8600\n",
      "Epoch 100: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1524 - accuracy: 0.8600 - val_loss: 1.1223 - val_accuracy: 0.7835 - lr: 8.4158e-07\n",
      "Epoch 101/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1503 - accuracy: 0.8615\n",
      "Epoch 101: val_loss did not improve from 1.12214\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 4.2078801243405906e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1502 - accuracy: 0.8615 - val_loss: 1.1239 - val_accuracy: 0.7831 - lr: 8.4158e-07\n",
      "Epoch 102/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1512 - accuracy: 0.8609\n",
      "Epoch 102: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1514 - accuracy: 0.8608 - val_loss: 1.1232 - val_accuracy: 0.7827 - lr: 4.2079e-07\n",
      "Epoch 103/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1494 - accuracy: 0.8629\n",
      "Epoch 103: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1495 - accuracy: 0.8629 - val_loss: 1.1228 - val_accuracy: 0.7830 - lr: 4.2079e-07\n",
      "Epoch 104/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1504 - accuracy: 0.8615\n",
      "Epoch 104: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1503 - accuracy: 0.8615 - val_loss: 1.1238 - val_accuracy: 0.7827 - lr: 4.2079e-07\n",
      "Epoch 105/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1492 - accuracy: 0.8603\n",
      "Epoch 105: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1492 - accuracy: 0.8603 - val_loss: 1.1227 - val_accuracy: 0.7830 - lr: 4.2079e-07\n",
      "Epoch 106/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1469 - accuracy: 0.8633\n",
      "Epoch 106: val_loss did not improve from 1.12214\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 2.1039400621702953e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1469 - accuracy: 0.8633 - val_loss: 1.1233 - val_accuracy: 0.7828 - lr: 4.2079e-07\n",
      "Epoch 107/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1505 - accuracy: 0.8618\n",
      "Epoch 107: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1507 - accuracy: 0.8618 - val_loss: 1.1228 - val_accuracy: 0.7827 - lr: 2.1039e-07\n",
      "Epoch 108/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1484 - accuracy: 0.8623\n",
      "Epoch 108: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1484 - accuracy: 0.8624 - val_loss: 1.1226 - val_accuracy: 0.7826 - lr: 2.1039e-07\n",
      "Epoch 109/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1484 - accuracy: 0.8622\n",
      "Epoch 109: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1484 - accuracy: 0.8623 - val_loss: 1.1222 - val_accuracy: 0.7828 - lr: 2.1039e-07\n",
      "Epoch 110/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1463 - accuracy: 0.8620\n",
      "Epoch 110: val_loss did not improve from 1.12214\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1463 - accuracy: 0.8620 - val_loss: 1.1236 - val_accuracy: 0.7825 - lr: 2.1039e-07\n",
      "Epoch 111/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1455 - accuracy: 0.8624\n",
      "Epoch 111: val_loss improved from 1.12214 to 1.12193, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1455 - accuracy: 0.8624 - val_loss: 1.1219 - val_accuracy: 0.7830 - lr: 2.1039e-07\n",
      "Epoch 112/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1488 - accuracy: 0.8618\n",
      "Epoch 112: val_loss did not improve from 1.12193\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1491 - accuracy: 0.8618 - val_loss: 1.1219 - val_accuracy: 0.7831 - lr: 2.1039e-07\n",
      "Epoch 113/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1459 - accuracy: 0.8617\n",
      "Epoch 113: val_loss improved from 1.12193 to 1.12178, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1458 - accuracy: 0.8617 - val_loss: 1.1218 - val_accuracy: 0.7830 - lr: 2.1039e-07\n",
      "Epoch 114/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1466 - accuracy: 0.8620\n",
      "Epoch 114: val_loss improved from 1.12178 to 1.12172, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1467 - accuracy: 0.8620 - val_loss: 1.1217 - val_accuracy: 0.7829 - lr: 2.1039e-07\n",
      "Epoch 115/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1453 - accuracy: 0.8636\n",
      "Epoch 115: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1454 - accuracy: 0.8636 - val_loss: 1.1229 - val_accuracy: 0.7828 - lr: 2.1039e-07\n",
      "Epoch 116/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1460 - accuracy: 0.8627\n",
      "Epoch 116: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1458 - accuracy: 0.8628 - val_loss: 1.1222 - val_accuracy: 0.7829 - lr: 2.1039e-07\n",
      "Epoch 117/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1457 - accuracy: 0.8611\n",
      "Epoch 117: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1458 - accuracy: 0.8611 - val_loss: 1.1226 - val_accuracy: 0.7829 - lr: 2.1039e-07\n",
      "Epoch 118/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1467 - accuracy: 0.8631\n",
      "Epoch 118: val_loss did not improve from 1.12172\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 1.0519700310851476e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1469 - accuracy: 0.8630 - val_loss: 1.1230 - val_accuracy: 0.7825 - lr: 2.1039e-07\n",
      "Epoch 119/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1496 - accuracy: 0.8610\n",
      "Epoch 119: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1496 - accuracy: 0.8610 - val_loss: 1.1225 - val_accuracy: 0.7827 - lr: 1.0520e-07\n",
      "Epoch 120/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1424 - accuracy: 0.8635\n",
      "Epoch 120: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1423 - accuracy: 0.8635 - val_loss: 1.1224 - val_accuracy: 0.7828 - lr: 1.0520e-07\n",
      "Epoch 121/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1481 - accuracy: 0.8618\n",
      "Epoch 121: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1482 - accuracy: 0.8618 - val_loss: 1.1221 - val_accuracy: 0.7828 - lr: 1.0520e-07\n",
      "Epoch 122/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1451 - accuracy: 0.8619\n",
      "Epoch 122: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1451 - accuracy: 0.8619 - val_loss: 1.1227 - val_accuracy: 0.7825 - lr: 1.0520e-07\n",
      "Epoch 123/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1438 - accuracy: 0.8626\n",
      "Epoch 123: val_loss did not improve from 1.12172\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1438 - accuracy: 0.8626 - val_loss: 1.1218 - val_accuracy: 0.7834 - lr: 1.0520e-07\n",
      "Epoch 124/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1461 - accuracy: 0.8630\n",
      "Epoch 124: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1459 - accuracy: 0.8630 - val_loss: 1.1222 - val_accuracy: 0.7826 - lr: 1.0000e-07\n",
      "Epoch 125/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1433 - accuracy: 0.8632\n",
      "Epoch 125: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1434 - accuracy: 0.8632 - val_loss: 1.1220 - val_accuracy: 0.7827 - lr: 1.0000e-07\n",
      "Epoch 126/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1402 - accuracy: 0.8641\n",
      "Epoch 126: val_loss did not improve from 1.12172\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1403 - accuracy: 0.8641 - val_loss: 1.1218 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 127/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1502 - accuracy: 0.8605\n",
      "Epoch 127: val_loss improved from 1.12172 to 1.12157, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1502 - accuracy: 0.8605 - val_loss: 1.1216 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 128/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1439 - accuracy: 0.8622\n",
      "Epoch 128: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1439 - accuracy: 0.8622 - val_loss: 1.1225 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 129/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1422 - accuracy: 0.8633\n",
      "Epoch 129: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1424 - accuracy: 0.8632 - val_loss: 1.1225 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 130/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1472 - accuracy: 0.8619\n",
      "Epoch 130: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1471 - accuracy: 0.8619 - val_loss: 1.1221 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 131/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1442 - accuracy: 0.8627\n",
      "Epoch 131: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1439 - accuracy: 0.8628 - val_loss: 1.1222 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 132/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1440 - accuracy: 0.8621\n",
      "Epoch 132: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1442 - accuracy: 0.8621 - val_loss: 1.1229 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 133/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1445 - accuracy: 0.8630\n",
      "Epoch 133: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1445 - accuracy: 0.8630 - val_loss: 1.1218 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 134/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1437 - accuracy: 0.8622\n",
      "Epoch 134: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1435 - accuracy: 0.8622 - val_loss: 1.1218 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 135/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1483 - accuracy: 0.8609\n",
      "Epoch 135: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1482 - accuracy: 0.8610 - val_loss: 1.1218 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 136/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1453 - accuracy: 0.8619\n",
      "Epoch 136: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1452 - accuracy: 0.8619 - val_loss: 1.1225 - val_accuracy: 0.7825 - lr: 1.0000e-07\n",
      "Epoch 137/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1451 - accuracy: 0.8622\n",
      "Epoch 137: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1450 - accuracy: 0.8622 - val_loss: 1.1220 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 138/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1473 - accuracy: 0.8613\n",
      "Epoch 138: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1474 - accuracy: 0.8613 - val_loss: 1.1218 - val_accuracy: 0.7827 - lr: 1.0000e-07\n",
      "Epoch 139/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1432 - accuracy: 0.8620\n",
      "Epoch 139: val_loss improved from 1.12157 to 1.12157, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.1431 - accuracy: 0.8620 - val_loss: 1.1216 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 140/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1459 - accuracy: 0.8620\n",
      "Epoch 140: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1458 - accuracy: 0.8621 - val_loss: 1.1223 - val_accuracy: 0.7824 - lr: 1.0000e-07\n",
      "Epoch 141/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1459 - accuracy: 0.8622\n",
      "Epoch 141: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1459 - accuracy: 0.8622 - val_loss: 1.1220 - val_accuracy: 0.7827 - lr: 1.0000e-07\n",
      "Epoch 142/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1416 - accuracy: 0.8633\n",
      "Epoch 142: val_loss did not improve from 1.12157\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1416 - accuracy: 0.8633 - val_loss: 1.1218 - val_accuracy: 0.7834 - lr: 1.0000e-07\n",
      "Epoch 143/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1423 - accuracy: 0.8627\n",
      "Epoch 143: val_loss improved from 1.12157 to 1.12134, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1425 - accuracy: 0.8625 - val_loss: 1.1213 - val_accuracy: 0.7831 - lr: 1.0000e-07\n",
      "Epoch 144/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1408 - accuracy: 0.8636\n",
      "Epoch 144: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1407 - accuracy: 0.8636 - val_loss: 1.1214 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 145/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1423 - accuracy: 0.8640\n",
      "Epoch 145: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1424 - accuracy: 0.8640 - val_loss: 1.1225 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 146/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1420 - accuracy: 0.8618\n",
      "Epoch 146: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1419 - accuracy: 0.8618 - val_loss: 1.1218 - val_accuracy: 0.7827 - lr: 1.0000e-07\n",
      "Epoch 147/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.1432 - accuracy: 0.8628\n",
      "Epoch 147: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1430 - accuracy: 0.8629 - val_loss: 1.1220 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 148/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1450 - accuracy: 0.8634\n",
      "Epoch 148: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1450 - accuracy: 0.8634 - val_loss: 1.1217 - val_accuracy: 0.7826 - lr: 1.0000e-07\n",
      "Epoch 149/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1433 - accuracy: 0.8624\n",
      "Epoch 149: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1433 - accuracy: 0.8624 - val_loss: 1.1225 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 150/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1424 - accuracy: 0.8625\n",
      "Epoch 150: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1423 - accuracy: 0.8625 - val_loss: 1.1220 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 151/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1436 - accuracy: 0.8624\n",
      "Epoch 151: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1434 - accuracy: 0.8624 - val_loss: 1.1223 - val_accuracy: 0.7832 - lr: 1.0000e-07\n",
      "Epoch 152/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1418 - accuracy: 0.8626\n",
      "Epoch 152: val_loss did not improve from 1.12134\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1417 - accuracy: 0.8626 - val_loss: 1.1216 - val_accuracy: 0.7834 - lr: 1.0000e-07\n",
      "Epoch 153/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1399 - accuracy: 0.8629\n",
      "Epoch 153: val_loss improved from 1.12134 to 1.12093, saving model to kfold_model/fold_4_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1399 - accuracy: 0.8629 - val_loss: 1.1209 - val_accuracy: 0.7835 - lr: 1.0000e-07\n",
      "Epoch 154/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1438 - accuracy: 0.8634\n",
      "Epoch 154: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1437 - accuracy: 0.8634 - val_loss: 1.1225 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 155/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1524 - accuracy: 0.8608\n",
      "Epoch 155: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1522 - accuracy: 0.8609 - val_loss: 1.1227 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 156/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1438 - accuracy: 0.8621\n",
      "Epoch 156: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1440 - accuracy: 0.8621 - val_loss: 1.1220 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 157/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1396 - accuracy: 0.8634\n",
      "Epoch 157: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1396 - accuracy: 0.8634 - val_loss: 1.1221 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 158/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1455 - accuracy: 0.8626\n",
      "Epoch 158: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1456 - accuracy: 0.8626 - val_loss: 1.1222 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 159/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1461 - accuracy: 0.8613\n",
      "Epoch 159: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1461 - accuracy: 0.8613 - val_loss: 1.1216 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 160/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1416 - accuracy: 0.8631\n",
      "Epoch 160: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1416 - accuracy: 0.8631 - val_loss: 1.1226 - val_accuracy: 0.7831 - lr: 1.0000e-07\n",
      "Epoch 161/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1423 - accuracy: 0.8628\n",
      "Epoch 161: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1424 - accuracy: 0.8627 - val_loss: 1.1219 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 162/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1416 - accuracy: 0.8622\n",
      "Epoch 162: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1415 - accuracy: 0.8623 - val_loss: 1.1218 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 163/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1436 - accuracy: 0.8631\n",
      "Epoch 163: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1436 - accuracy: 0.8632 - val_loss: 1.1214 - val_accuracy: 0.7836 - lr: 1.0000e-07\n",
      "Epoch 164/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1427 - accuracy: 0.8609\n",
      "Epoch 164: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1431 - accuracy: 0.8609 - val_loss: 1.1216 - val_accuracy: 0.7832 - lr: 1.0000e-07\n",
      "Epoch 165/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1418 - accuracy: 0.8629\n",
      "Epoch 165: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1418 - accuracy: 0.8629 - val_loss: 1.1216 - val_accuracy: 0.7832 - lr: 1.0000e-07\n",
      "Epoch 166/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1428 - accuracy: 0.8627\n",
      "Epoch 166: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1427 - accuracy: 0.8627 - val_loss: 1.1216 - val_accuracy: 0.7835 - lr: 1.0000e-07\n",
      "Epoch 167/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1401 - accuracy: 0.8629\n",
      "Epoch 167: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1401 - accuracy: 0.8629 - val_loss: 1.1215 - val_accuracy: 0.7835 - lr: 1.0000e-07\n",
      "Epoch 168/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1401 - accuracy: 0.8630\n",
      "Epoch 168: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1401 - accuracy: 0.8630 - val_loss: 1.1220 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 169/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1466 - accuracy: 0.8622\n",
      "Epoch 169: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1466 - accuracy: 0.8622 - val_loss: 1.1218 - val_accuracy: 0.7835 - lr: 1.0000e-07\n",
      "Epoch 170/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1440 - accuracy: 0.8625\n",
      "Epoch 170: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1440 - accuracy: 0.8625 - val_loss: 1.1218 - val_accuracy: 0.7834 - lr: 1.0000e-07\n",
      "Epoch 171/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1442 - accuracy: 0.8612\n",
      "Epoch 171: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1445 - accuracy: 0.8612 - val_loss: 1.1219 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 172/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1429 - accuracy: 0.8624\n",
      "Epoch 172: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1430 - accuracy: 0.8624 - val_loss: 1.1217 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 173/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1398 - accuracy: 0.8631\n",
      "Epoch 173: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1398 - accuracy: 0.8631 - val_loss: 1.1209 - val_accuracy: 0.7835 - lr: 1.0000e-07\n",
      "Epoch 174/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1419 - accuracy: 0.8628\n",
      "Epoch 174: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1418 - accuracy: 0.8627 - val_loss: 1.1213 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 175/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1398 - accuracy: 0.8635\n",
      "Epoch 175: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1399 - accuracy: 0.8635 - val_loss: 1.1222 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 176/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1423 - accuracy: 0.8629\n",
      "Epoch 176: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1423 - accuracy: 0.8629 - val_loss: 1.1216 - val_accuracy: 0.7831 - lr: 1.0000e-07\n",
      "Epoch 177/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1431 - accuracy: 0.8617\n",
      "Epoch 177: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1432 - accuracy: 0.8616 - val_loss: 1.1218 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 178/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1438 - accuracy: 0.8629\n",
      "Epoch 178: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1440 - accuracy: 0.8629 - val_loss: 1.1218 - val_accuracy: 0.7834 - lr: 1.0000e-07\n",
      "Epoch 179/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1401 - accuracy: 0.8621\n",
      "Epoch 179: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1401 - accuracy: 0.8621 - val_loss: 1.1217 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 180/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.1418 - accuracy: 0.8639\n",
      "Epoch 180: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1420 - accuracy: 0.8638 - val_loss: 1.1216 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 181/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1433 - accuracy: 0.8628\n",
      "Epoch 181: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1431 - accuracy: 0.8629 - val_loss: 1.1216 - val_accuracy: 0.7834 - lr: 1.0000e-07\n",
      "Epoch 182/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1408 - accuracy: 0.8632\n",
      "Epoch 182: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1407 - accuracy: 0.8632 - val_loss: 1.1224 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 183/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1448 - accuracy: 0.8624\n",
      "Epoch 183: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1446 - accuracy: 0.8624 - val_loss: 1.1216 - val_accuracy: 0.7835 - lr: 1.0000e-07\n",
      "Epoch 184/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1432 - accuracy: 0.8625\n",
      "Epoch 184: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1433 - accuracy: 0.8625 - val_loss: 1.1222 - val_accuracy: 0.7833 - lr: 1.0000e-07\n",
      "Epoch 185/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.1429 - accuracy: 0.8617\n",
      "Epoch 185: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1428 - accuracy: 0.8618 - val_loss: 1.1224 - val_accuracy: 0.7828 - lr: 1.0000e-07\n",
      "Epoch 186/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1418 - accuracy: 0.8626\n",
      "Epoch 186: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1420 - accuracy: 0.8625 - val_loss: 1.1219 - val_accuracy: 0.7832 - lr: 1.0000e-07\n",
      "Epoch 187/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1407 - accuracy: 0.8618\n",
      "Epoch 187: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1407 - accuracy: 0.8618 - val_loss: 1.1228 - val_accuracy: 0.7831 - lr: 1.0000e-07\n",
      "Epoch 188/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1414 - accuracy: 0.8633\n",
      "Epoch 188: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1415 - accuracy: 0.8633 - val_loss: 1.1224 - val_accuracy: 0.7829 - lr: 1.0000e-07\n",
      "Epoch 189/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1414 - accuracy: 0.8632\n",
      "Epoch 189: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1413 - accuracy: 0.8632 - val_loss: 1.1226 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 190/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1396 - accuracy: 0.8645\n",
      "Epoch 190: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1396 - accuracy: 0.8645 - val_loss: 1.1216 - val_accuracy: 0.7832 - lr: 1.0000e-07\n",
      "Epoch 191/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1420 - accuracy: 0.8634\n",
      "Epoch 191: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1420 - accuracy: 0.8634 - val_loss: 1.1216 - val_accuracy: 0.7830 - lr: 1.0000e-07\n",
      "Epoch 192/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1412 - accuracy: 0.8636\n",
      "Epoch 192: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1412 - accuracy: 0.8636 - val_loss: 1.1221 - val_accuracy: 0.7840 - lr: 1.0000e-07\n",
      "Epoch 193/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1441 - accuracy: 0.8624\n",
      "Epoch 193: val_loss did not improve from 1.12093\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1441 - accuracy: 0.8624 - val_loss: 1.1213 - val_accuracy: 0.7836 - lr: 1.0000e-07\n",
      "Epoch 193: early stopping\n",
      "Training fold 5...\n",
      "Epoch 1/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 16.6511 - accuracy: 0.3558\n",
      "Epoch 1: val_loss improved from inf to 11.82998, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 23s 7ms/step - loss: 16.6511 - accuracy: 0.3558 - val_loss: 11.8300 - val_accuracy: 0.4667 - lr: 2.1544e-04\n",
      "Epoch 2/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 10.8144 - accuracy: 0.5139\n",
      "Epoch 2: val_loss improved from 11.82998 to 7.72365, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 10.8130 - accuracy: 0.5139 - val_loss: 7.7236 - val_accuracy: 0.5577 - lr: 2.1544e-04\n",
      "Epoch 3/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 7.7343 - accuracy: 0.5792\n",
      "Epoch 3: val_loss improved from 7.72365 to 5.75083, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 7.7326 - accuracy: 0.5792 - val_loss: 5.7508 - val_accuracy: 0.6043 - lr: 2.1544e-04\n",
      "Epoch 4/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 6.1371 - accuracy: 0.6063\n",
      "Epoch 4: val_loss improved from 5.75083 to 4.74270, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 6.1360 - accuracy: 0.6064 - val_loss: 4.7427 - val_accuracy: 0.6310 - lr: 2.1544e-04\n",
      "Epoch 5/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 5.0966 - accuracy: 0.6324\n",
      "Epoch 5: val_loss improved from 4.74270 to 3.85162, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 5.0966 - accuracy: 0.6324 - val_loss: 3.8516 - val_accuracy: 0.6519 - lr: 2.1544e-04\n",
      "Epoch 6/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 4.5004 - accuracy: 0.6396\n",
      "Epoch 6: val_loss improved from 3.85162 to 3.39691, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 4.5068 - accuracy: 0.6397 - val_loss: 3.3969 - val_accuracy: 0.6405 - lr: 2.1544e-04\n",
      "Epoch 7/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 4.1757 - accuracy: 0.6495\n",
      "Epoch 7: val_loss improved from 3.39691 to 3.10310, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 4.1756 - accuracy: 0.6494 - val_loss: 3.1031 - val_accuracy: 0.6957 - lr: 2.1544e-04\n",
      "Epoch 8/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 3.8870 - accuracy: 0.6586\n",
      "Epoch 8: val_loss improved from 3.10310 to 2.92581, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.8868 - accuracy: 0.6587 - val_loss: 2.9258 - val_accuracy: 0.6535 - lr: 2.1544e-04\n",
      "Epoch 9/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 3.6224 - accuracy: 0.6635\n",
      "Epoch 9: val_loss improved from 2.92581 to 2.83742, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 3.6296 - accuracy: 0.6635 - val_loss: 2.8374 - val_accuracy: 0.6394 - lr: 2.1544e-04\n",
      "Epoch 10/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 3.5877 - accuracy: 0.6626\n",
      "Epoch 10: val_loss improved from 2.83742 to 2.53338, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 3.5873 - accuracy: 0.6627 - val_loss: 2.5334 - val_accuracy: 0.6999 - lr: 2.1544e-04\n",
      "Epoch 11/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 3.3962 - accuracy: 0.6701\n",
      "Epoch 11: val_loss did not improve from 2.53338\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 3.3968 - accuracy: 0.6701 - val_loss: 2.7723 - val_accuracy: 0.6586 - lr: 2.1544e-04\n",
      "Epoch 12/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 3.2708 - accuracy: 0.6746\n",
      "Epoch 12: val_loss did not improve from 2.53338\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.2719 - accuracy: 0.6745 - val_loss: 2.9209 - val_accuracy: 0.6099 - lr: 2.1544e-04\n",
      "Epoch 13/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 3.1174 - accuracy: 0.6820\n",
      "Epoch 13: val_loss improved from 2.53338 to 2.21229, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 3.1176 - accuracy: 0.6820 - val_loss: 2.2123 - val_accuracy: 0.6963 - lr: 2.1544e-04\n",
      "Epoch 14/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 3.2887 - accuracy: 0.6664\n",
      "Epoch 14: val_loss did not improve from 2.21229\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.2882 - accuracy: 0.6666 - val_loss: 2.2354 - val_accuracy: 0.6946 - lr: 2.1544e-04\n",
      "Epoch 15/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 3.0504 - accuracy: 0.6841\n",
      "Epoch 15: val_loss did not improve from 2.21229\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0506 - accuracy: 0.6840 - val_loss: 2.4035 - val_accuracy: 0.6883 - lr: 2.1544e-04\n",
      "Epoch 16/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 3.0069 - accuracy: 0.6841\n",
      "Epoch 16: val_loss did not improve from 2.21229\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0068 - accuracy: 0.6841 - val_loss: 2.2578 - val_accuracy: 0.6915 - lr: 2.1544e-04\n",
      "Epoch 17/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.9023 - accuracy: 0.6889\n",
      "Epoch 17: val_loss improved from 2.21229 to 2.19086, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.9022 - accuracy: 0.6889 - val_loss: 2.1909 - val_accuracy: 0.6949 - lr: 2.1544e-04\n",
      "Epoch 18/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.9813 - accuracy: 0.6819\n",
      "Epoch 18: val_loss improved from 2.19086 to 2.18341, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.9806 - accuracy: 0.6821 - val_loss: 2.1834 - val_accuracy: 0.6891 - lr: 2.1544e-04\n",
      "Epoch 19/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 2.8574 - accuracy: 0.6885\n",
      "Epoch 19: val_loss improved from 2.18341 to 1.96530, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8571 - accuracy: 0.6884 - val_loss: 1.9653 - val_accuracy: 0.7102 - lr: 2.1544e-04\n",
      "Epoch 20/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 2.9360 - accuracy: 0.6848\n",
      "Epoch 20: val_loss did not improve from 1.96530\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.9359 - accuracy: 0.6848 - val_loss: 2.2361 - val_accuracy: 0.6689 - lr: 2.1544e-04\n",
      "Epoch 21/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.7618 - accuracy: 0.6949\n",
      "Epoch 21: val_loss improved from 1.96530 to 1.87626, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7614 - accuracy: 0.6950 - val_loss: 1.8763 - val_accuracy: 0.7126 - lr: 2.1544e-04\n",
      "Epoch 22/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.7745 - accuracy: 0.6937\n",
      "Epoch 22: val_loss did not improve from 1.87626\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7743 - accuracy: 0.6937 - val_loss: 2.0485 - val_accuracy: 0.7015 - lr: 2.1544e-04\n",
      "Epoch 23/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 2.7562 - accuracy: 0.6951\n",
      "Epoch 23: val_loss did not improve from 1.87626\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7562 - accuracy: 0.6951 - val_loss: 2.1805 - val_accuracy: 0.7010 - lr: 2.1544e-04\n",
      "Epoch 24/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 2.7371 - accuracy: 0.6942\n",
      "Epoch 24: val_loss did not improve from 1.87626\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7375 - accuracy: 0.6943 - val_loss: 1.9325 - val_accuracy: 0.7196 - lr: 2.1544e-04\n",
      "Epoch 25/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.7018 - accuracy: 0.7013\n",
      "Epoch 25: val_loss did not improve from 1.87626\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7020 - accuracy: 0.7012 - val_loss: 2.0354 - val_accuracy: 0.6782 - lr: 2.1544e-04\n",
      "Epoch 26/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.7486 - accuracy: 0.6926\n",
      "Epoch 26: val_loss did not improve from 1.87626\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010772173118311912.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7488 - accuracy: 0.6926 - val_loss: 2.1688 - val_accuracy: 0.6989 - lr: 2.1544e-04\n",
      "Epoch 27/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.4841 - accuracy: 0.7179\n",
      "Epoch 27: val_loss improved from 1.87626 to 1.69634, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 2.4841 - accuracy: 0.7178 - val_loss: 1.6963 - val_accuracy: 0.7224 - lr: 1.0772e-04\n",
      "Epoch 28/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 2.2645 - accuracy: 0.7285\n",
      "Epoch 28: val_loss improved from 1.69634 to 1.56672, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.2643 - accuracy: 0.7285 - val_loss: 1.5667 - val_accuracy: 0.7331 - lr: 1.0772e-04\n",
      "Epoch 29/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 2.1540 - accuracy: 0.7344\n",
      "Epoch 29: val_loss did not improve from 1.56672\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1537 - accuracy: 0.7344 - val_loss: 1.6073 - val_accuracy: 0.7256 - lr: 1.0772e-04\n",
      "Epoch 30/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.1717 - accuracy: 0.7336\n",
      "Epoch 30: val_loss did not improve from 1.56672\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1720 - accuracy: 0.7336 - val_loss: 1.7559 - val_accuracy: 0.7108 - lr: 1.0772e-04\n",
      "Epoch 31/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.0982 - accuracy: 0.7405\n",
      "Epoch 31: val_loss improved from 1.56672 to 1.51899, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.0977 - accuracy: 0.7406 - val_loss: 1.5190 - val_accuracy: 0.7319 - lr: 1.0772e-04\n",
      "Epoch 32/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 2.0817 - accuracy: 0.7403\n",
      "Epoch 32: val_loss did not improve from 1.51899\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.0817 - accuracy: 0.7403 - val_loss: 1.5908 - val_accuracy: 0.7359 - lr: 1.0772e-04\n",
      "Epoch 33/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 2.1130 - accuracy: 0.7413\n",
      "Epoch 33: val_loss did not improve from 1.51899\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.1130 - accuracy: 0.7413 - val_loss: 1.5886 - val_accuracy: 0.7231 - lr: 1.0772e-04\n",
      "Epoch 34/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.0503 - accuracy: 0.7422\n",
      "Epoch 34: val_loss did not improve from 1.51899\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.0505 - accuracy: 0.7422 - val_loss: 1.6262 - val_accuracy: 0.7199 - lr: 1.0772e-04\n",
      "Epoch 35/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.0935 - accuracy: 0.7442\n",
      "Epoch 35: val_loss did not improve from 1.51899\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.0935 - accuracy: 0.7442 - val_loss: 1.5711 - val_accuracy: 0.7241 - lr: 1.0772e-04\n",
      "Epoch 36/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 2.0020 - accuracy: 0.7471\n",
      "Epoch 36: val_loss did not improve from 1.51899\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 5.386086559155956e-05.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.0020 - accuracy: 0.7472 - val_loss: 1.5347 - val_accuracy: 0.7303 - lr: 1.0772e-04\n",
      "Epoch 37/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.8574 - accuracy: 0.7645\n",
      "Epoch 37: val_loss improved from 1.51899 to 1.39802, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.8574 - accuracy: 0.7645 - val_loss: 1.3980 - val_accuracy: 0.7490 - lr: 5.3861e-05\n",
      "Epoch 38/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.8064 - accuracy: 0.7717\n",
      "Epoch 38: val_loss improved from 1.39802 to 1.31173, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.8068 - accuracy: 0.7718 - val_loss: 1.3117 - val_accuracy: 0.7550 - lr: 5.3861e-05\n",
      "Epoch 39/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.7703 - accuracy: 0.7715\n",
      "Epoch 39: val_loss did not improve from 1.31173\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7701 - accuracy: 0.7716 - val_loss: 1.3151 - val_accuracy: 0.7614 - lr: 5.3861e-05\n",
      "Epoch 40/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.7237 - accuracy: 0.7779\n",
      "Epoch 40: val_loss improved from 1.31173 to 1.27774, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.7234 - accuracy: 0.7779 - val_loss: 1.2777 - val_accuracy: 0.7616 - lr: 5.3861e-05\n",
      "Epoch 41/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.7107 - accuracy: 0.7772\n",
      "Epoch 41: val_loss did not improve from 1.27774\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7109 - accuracy: 0.7772 - val_loss: 1.3438 - val_accuracy: 0.7407 - lr: 5.3861e-05\n",
      "Epoch 42/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.6870 - accuracy: 0.7807\n",
      "Epoch 42: val_loss did not improve from 1.27774\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.6868 - accuracy: 0.7808 - val_loss: 1.2963 - val_accuracy: 0.7578 - lr: 5.3861e-05\n",
      "Epoch 43/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.7105 - accuracy: 0.7789\n",
      "Epoch 43: val_loss did not improve from 1.27774\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.7104 - accuracy: 0.7789 - val_loss: 1.3512 - val_accuracy: 0.7524 - lr: 5.3861e-05\n",
      "Epoch 44/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.6545 - accuracy: 0.7857\n",
      "Epoch 44: val_loss did not improve from 1.27774\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.6544 - accuracy: 0.7858 - val_loss: 1.2811 - val_accuracy: 0.7566 - lr: 5.3861e-05\n",
      "Epoch 45/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.6644 - accuracy: 0.7854\n",
      "Epoch 45: val_loss did not improve from 1.27774\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.693043279577978e-05.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.6644 - accuracy: 0.7854 - val_loss: 1.3309 - val_accuracy: 0.7516 - lr: 5.3861e-05\n",
      "Epoch 46/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.5683 - accuracy: 0.8005\n",
      "Epoch 46: val_loss improved from 1.27774 to 1.24304, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.5682 - accuracy: 0.8005 - val_loss: 1.2430 - val_accuracy: 0.7641 - lr: 2.6930e-05\n",
      "Epoch 47/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.8046\n",
      "Epoch 47: val_loss improved from 1.24304 to 1.23407, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.5129 - accuracy: 0.8045 - val_loss: 1.2341 - val_accuracy: 0.7637 - lr: 2.6930e-05\n",
      "Epoch 48/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.4955 - accuracy: 0.8056\n",
      "Epoch 48: val_loss improved from 1.23407 to 1.22733, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 20s 7ms/step - loss: 1.4955 - accuracy: 0.8056 - val_loss: 1.2273 - val_accuracy: 0.7619 - lr: 2.6930e-05\n",
      "Epoch 49/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.8102\n",
      "Epoch 49: val_loss improved from 1.22733 to 1.22021, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4714 - accuracy: 0.8102 - val_loss: 1.2202 - val_accuracy: 0.7621 - lr: 2.6930e-05\n",
      "Epoch 50/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.4657 - accuracy: 0.8109\n",
      "Epoch 50: val_loss improved from 1.22021 to 1.20874, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4656 - accuracy: 0.8109 - val_loss: 1.2087 - val_accuracy: 0.7690 - lr: 2.6930e-05\n",
      "Epoch 51/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.4594 - accuracy: 0.8110\n",
      "Epoch 51: val_loss did not improve from 1.20874\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4595 - accuracy: 0.8110 - val_loss: 1.2095 - val_accuracy: 0.7663 - lr: 2.6930e-05\n",
      "Epoch 52/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.4361 - accuracy: 0.8155\n",
      "Epoch 52: val_loss improved from 1.20874 to 1.19335, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4361 - accuracy: 0.8155 - val_loss: 1.1933 - val_accuracy: 0.7730 - lr: 2.6930e-05\n",
      "Epoch 53/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.4309 - accuracy: 0.8169\n",
      "Epoch 53: val_loss did not improve from 1.19335\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4312 - accuracy: 0.8169 - val_loss: 1.2059 - val_accuracy: 0.7679 - lr: 2.6930e-05\n",
      "Epoch 54/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.4227 - accuracy: 0.8188\n",
      "Epoch 54: val_loss did not improve from 1.19335\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4225 - accuracy: 0.8188 - val_loss: 1.2281 - val_accuracy: 0.7618 - lr: 2.6930e-05\n",
      "Epoch 55/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.4106 - accuracy: 0.8204\n",
      "Epoch 55: val_loss did not improve from 1.19335\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.4111 - accuracy: 0.8203 - val_loss: 1.2236 - val_accuracy: 0.7664 - lr: 2.6930e-05\n",
      "Epoch 56/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.3986 - accuracy: 0.8220\n",
      "Epoch 56: val_loss did not improve from 1.19335\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3987 - accuracy: 0.8220 - val_loss: 1.2206 - val_accuracy: 0.7652 - lr: 2.6930e-05\n",
      "Epoch 57/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.8233\n",
      "Epoch 57: val_loss did not improve from 1.19335\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.346521639788989e-05.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3895 - accuracy: 0.8233 - val_loss: 1.2140 - val_accuracy: 0.7688 - lr: 2.6930e-05\n",
      "Epoch 58/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.3301 - accuracy: 0.8333\n",
      "Epoch 58: val_loss improved from 1.19335 to 1.17797, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3302 - accuracy: 0.8332 - val_loss: 1.1780 - val_accuracy: 0.7733 - lr: 1.3465e-05\n",
      "Epoch 59/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.3190 - accuracy: 0.8336\n",
      "Epoch 59: val_loss improved from 1.17797 to 1.16917, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.3189 - accuracy: 0.8337 - val_loss: 1.1692 - val_accuracy: 0.7757 - lr: 1.3465e-05\n",
      "Epoch 60/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.2958 - accuracy: 0.8387\n",
      "Epoch 60: val_loss improved from 1.16917 to 1.16555, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2958 - accuracy: 0.8387 - val_loss: 1.1655 - val_accuracy: 0.7762 - lr: 1.3465e-05\n",
      "Epoch 61/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.2857 - accuracy: 0.8404\n",
      "Epoch 61: val_loss did not improve from 1.16555\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2855 - accuracy: 0.8405 - val_loss: 1.1680 - val_accuracy: 0.7749 - lr: 1.3465e-05\n",
      "Epoch 62/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.2850 - accuracy: 0.8406\n",
      "Epoch 62: val_loss did not improve from 1.16555\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2855 - accuracy: 0.8404 - val_loss: 1.1694 - val_accuracy: 0.7745 - lr: 1.3465e-05\n",
      "Epoch 63/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.2816 - accuracy: 0.8405\n",
      "Epoch 63: val_loss did not improve from 1.16555\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2814 - accuracy: 0.8405 - val_loss: 1.1660 - val_accuracy: 0.7761 - lr: 1.3465e-05\n",
      "Epoch 64/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.2719 - accuracy: 0.8437\n",
      "Epoch 64: val_loss did not improve from 1.16555\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2718 - accuracy: 0.8438 - val_loss: 1.1742 - val_accuracy: 0.7722 - lr: 1.3465e-05\n",
      "Epoch 65/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.2661 - accuracy: 0.8441\n",
      "Epoch 65: val_loss did not improve from 1.16555\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.732608198944945e-06.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2660 - accuracy: 0.8441 - val_loss: 1.1662 - val_accuracy: 0.7750 - lr: 1.3465e-05\n",
      "Epoch 66/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.2308 - accuracy: 0.8503\n",
      "Epoch 66: val_loss improved from 1.16555 to 1.16072, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2310 - accuracy: 0.8502 - val_loss: 1.1607 - val_accuracy: 0.7756 - lr: 6.7326e-06\n",
      "Epoch 67/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.2218 - accuracy: 0.8506\n",
      "Epoch 67: val_loss did not improve from 1.16072\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2218 - accuracy: 0.8506 - val_loss: 1.1618 - val_accuracy: 0.7757 - lr: 6.7326e-06\n",
      "Epoch 68/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.2155 - accuracy: 0.8527\n",
      "Epoch 68: val_loss improved from 1.16072 to 1.15974, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2155 - accuracy: 0.8526 - val_loss: 1.1597 - val_accuracy: 0.7739 - lr: 6.7326e-06\n",
      "Epoch 69/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.2096 - accuracy: 0.8529\n",
      "Epoch 69: val_loss improved from 1.15974 to 1.15899, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2096 - accuracy: 0.8529 - val_loss: 1.1590 - val_accuracy: 0.7775 - lr: 6.7326e-06\n",
      "Epoch 70/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.2071 - accuracy: 0.8539\n",
      "Epoch 70: val_loss did not improve from 1.15899\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2072 - accuracy: 0.8539 - val_loss: 1.1614 - val_accuracy: 0.7746 - lr: 6.7326e-06\n",
      "Epoch 71/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.2022 - accuracy: 0.8537\n",
      "Epoch 71: val_loss improved from 1.15899 to 1.15315, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2022 - accuracy: 0.8537 - val_loss: 1.1532 - val_accuracy: 0.7792 - lr: 6.7326e-06\n",
      "Epoch 72/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.2000 - accuracy: 0.8556\n",
      "Epoch 72: val_loss did not improve from 1.15315\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.2001 - accuracy: 0.8556 - val_loss: 1.1554 - val_accuracy: 0.7777 - lr: 6.7326e-06\n",
      "Epoch 73/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1993 - accuracy: 0.8559\n",
      "Epoch 73: val_loss did not improve from 1.15315\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1990 - accuracy: 0.8560 - val_loss: 1.1546 - val_accuracy: 0.7784 - lr: 6.7326e-06\n",
      "Epoch 74/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1915 - accuracy: 0.8563\n",
      "Epoch 74: val_loss did not improve from 1.15315\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1915 - accuracy: 0.8563 - val_loss: 1.1565 - val_accuracy: 0.7758 - lr: 6.7326e-06\n",
      "Epoch 75/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1880 - accuracy: 0.8578\n",
      "Epoch 75: val_loss did not improve from 1.15315\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1881 - accuracy: 0.8578 - val_loss: 1.1550 - val_accuracy: 0.7766 - lr: 6.7326e-06\n",
      "Epoch 76/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1867 - accuracy: 0.8579\n",
      "Epoch 76: val_loss improved from 1.15315 to 1.14892, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1867 - accuracy: 0.8580 - val_loss: 1.1489 - val_accuracy: 0.7796 - lr: 6.7326e-06\n",
      "Epoch 77/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1851 - accuracy: 0.8590\n",
      "Epoch 77: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1851 - accuracy: 0.8590 - val_loss: 1.1545 - val_accuracy: 0.7787 - lr: 6.7326e-06\n",
      "Epoch 78/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1787 - accuracy: 0.8590\n",
      "Epoch 78: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1789 - accuracy: 0.8590 - val_loss: 1.1593 - val_accuracy: 0.7772 - lr: 6.7326e-06\n",
      "Epoch 79/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1754 - accuracy: 0.8598\n",
      "Epoch 79: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1752 - accuracy: 0.8599 - val_loss: 1.1664 - val_accuracy: 0.7762 - lr: 6.7326e-06\n",
      "Epoch 80/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1699 - accuracy: 0.8594\n",
      "Epoch 80: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1698 - accuracy: 0.8594 - val_loss: 1.1525 - val_accuracy: 0.7814 - lr: 6.7326e-06\n",
      "Epoch 81/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1731 - accuracy: 0.8589\n",
      "Epoch 81: val_loss did not improve from 1.14892\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.3663040994724724e-06.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1730 - accuracy: 0.8589 - val_loss: 1.1577 - val_accuracy: 0.7777 - lr: 6.7326e-06\n",
      "Epoch 82/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1520 - accuracy: 0.8647\n",
      "Epoch 82: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1523 - accuracy: 0.8647 - val_loss: 1.1507 - val_accuracy: 0.7793 - lr: 3.3663e-06\n",
      "Epoch 83/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1479 - accuracy: 0.8637\n",
      "Epoch 83: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1479 - accuracy: 0.8638 - val_loss: 1.1566 - val_accuracy: 0.7763 - lr: 3.3663e-06\n",
      "Epoch 84/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1424 - accuracy: 0.8662\n",
      "Epoch 84: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1424 - accuracy: 0.8662 - val_loss: 1.1514 - val_accuracy: 0.7777 - lr: 3.3663e-06\n",
      "Epoch 85/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1444 - accuracy: 0.8645\n",
      "Epoch 85: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1441 - accuracy: 0.8646 - val_loss: 1.1508 - val_accuracy: 0.7793 - lr: 3.3663e-06\n",
      "Epoch 86/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1385 - accuracy: 0.8655\n",
      "Epoch 86: val_loss did not improve from 1.14892\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.6831520497362362e-06.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1384 - accuracy: 0.8654 - val_loss: 1.1532 - val_accuracy: 0.7792 - lr: 3.3663e-06\n",
      "Epoch 87/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1288 - accuracy: 0.8683\n",
      "Epoch 87: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1288 - accuracy: 0.8683 - val_loss: 1.1505 - val_accuracy: 0.7779 - lr: 1.6832e-06\n",
      "Epoch 88/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1293 - accuracy: 0.8684\n",
      "Epoch 88: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1292 - accuracy: 0.8684 - val_loss: 1.1495 - val_accuracy: 0.7782 - lr: 1.6832e-06\n",
      "Epoch 89/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1278 - accuracy: 0.8679\n",
      "Epoch 89: val_loss did not improve from 1.14892\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1280 - accuracy: 0.8679 - val_loss: 1.1495 - val_accuracy: 0.7790 - lr: 1.6832e-06\n",
      "Epoch 90/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1247 - accuracy: 0.8678\n",
      "Epoch 90: val_loss improved from 1.14892 to 1.14724, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1248 - accuracy: 0.8678 - val_loss: 1.1472 - val_accuracy: 0.7791 - lr: 1.6832e-06\n",
      "Epoch 91/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1245 - accuracy: 0.8686\n",
      "Epoch 91: val_loss improved from 1.14724 to 1.14558, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 18s 7ms/step - loss: 1.1245 - accuracy: 0.8686 - val_loss: 1.1456 - val_accuracy: 0.7808 - lr: 1.6832e-06\n",
      "Epoch 92/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1206 - accuracy: 0.8696\n",
      "Epoch 92: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 18s 6ms/step - loss: 1.1208 - accuracy: 0.8695 - val_loss: 1.1466 - val_accuracy: 0.7793 - lr: 1.6832e-06\n",
      "Epoch 93/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1218 - accuracy: 0.8687\n",
      "Epoch 93: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1222 - accuracy: 0.8687 - val_loss: 1.1476 - val_accuracy: 0.7791 - lr: 1.6832e-06\n",
      "Epoch 94/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1213 - accuracy: 0.8694\n",
      "Epoch 94: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1214 - accuracy: 0.8694 - val_loss: 1.1484 - val_accuracy: 0.7801 - lr: 1.6832e-06\n",
      "Epoch 95/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1224 - accuracy: 0.8684\n",
      "Epoch 95: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 18s 7ms/step - loss: 1.1225 - accuracy: 0.8684 - val_loss: 1.1506 - val_accuracy: 0.7779 - lr: 1.6832e-06\n",
      "Epoch 96/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1163 - accuracy: 0.8707\n",
      "Epoch 96: val_loss did not improve from 1.14558\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 8.415760248681181e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1163 - accuracy: 0.8707 - val_loss: 1.1475 - val_accuracy: 0.7790 - lr: 1.6832e-06\n",
      "Epoch 97/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1116 - accuracy: 0.8711\n",
      "Epoch 97: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1115 - accuracy: 0.8711 - val_loss: 1.1485 - val_accuracy: 0.7793 - lr: 8.4158e-07\n",
      "Epoch 98/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1131 - accuracy: 0.8711\n",
      "Epoch 98: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1130 - accuracy: 0.8711 - val_loss: 1.1468 - val_accuracy: 0.7796 - lr: 8.4158e-07\n",
      "Epoch 99/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1107 - accuracy: 0.8722\n",
      "Epoch 99: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1109 - accuracy: 0.8722 - val_loss: 1.1473 - val_accuracy: 0.7799 - lr: 8.4158e-07\n",
      "Epoch 100/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1121 - accuracy: 0.8709\n",
      "Epoch 100: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1121 - accuracy: 0.8709 - val_loss: 1.1482 - val_accuracy: 0.7799 - lr: 8.4158e-07\n",
      "Epoch 101/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1112 - accuracy: 0.8706\n",
      "Epoch 101: val_loss did not improve from 1.14558\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 4.2078801243405906e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1112 - accuracy: 0.8706 - val_loss: 1.1464 - val_accuracy: 0.7805 - lr: 8.4158e-07\n",
      "Epoch 102/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1122 - accuracy: 0.8707\n",
      "Epoch 102: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1124 - accuracy: 0.8707 - val_loss: 1.1461 - val_accuracy: 0.7803 - lr: 4.2079e-07\n",
      "Epoch 103/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1113 - accuracy: 0.8714\n",
      "Epoch 103: val_loss did not improve from 1.14558\n",
      "2830/2830 [==============================] - 18s 7ms/step - loss: 1.1113 - accuracy: 0.8714 - val_loss: 1.1461 - val_accuracy: 0.7804 - lr: 4.2079e-07\n",
      "Epoch 104/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1086 - accuracy: 0.8710\n",
      "Epoch 104: val_loss improved from 1.14558 to 1.14489, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1086 - accuracy: 0.8710 - val_loss: 1.1449 - val_accuracy: 0.7798 - lr: 4.2079e-07\n",
      "Epoch 105/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1075 - accuracy: 0.8706\n",
      "Epoch 105: val_loss did not improve from 1.14489\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1074 - accuracy: 0.8707 - val_loss: 1.1452 - val_accuracy: 0.7801 - lr: 4.2079e-07\n",
      "Epoch 106/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.1080 - accuracy: 0.8718\n",
      "Epoch 106: val_loss did not improve from 1.14489\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1080 - accuracy: 0.8717 - val_loss: 1.1454 - val_accuracy: 0.7806 - lr: 4.2079e-07\n",
      "Epoch 107/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1070 - accuracy: 0.8717\n",
      "Epoch 107: val_loss improved from 1.14489 to 1.14462, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1068 - accuracy: 0.8717 - val_loss: 1.1446 - val_accuracy: 0.7794 - lr: 4.2079e-07\n",
      "Epoch 108/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1053 - accuracy: 0.8715\n",
      "Epoch 108: val_loss did not improve from 1.14462\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1052 - accuracy: 0.8715 - val_loss: 1.1460 - val_accuracy: 0.7799 - lr: 4.2079e-07\n",
      "Epoch 109/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1039 - accuracy: 0.8710\n",
      "Epoch 109: val_loss did not improve from 1.14462\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1039 - accuracy: 0.8710 - val_loss: 1.1450 - val_accuracy: 0.7797 - lr: 4.2079e-07\n",
      "Epoch 110/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1042 - accuracy: 0.8730\n",
      "Epoch 110: val_loss did not improve from 1.14462\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1044 - accuracy: 0.8730 - val_loss: 1.1455 - val_accuracy: 0.7797 - lr: 4.2079e-07\n",
      "Epoch 111/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1058 - accuracy: 0.8718\n",
      "Epoch 111: val_loss did not improve from 1.14462\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1058 - accuracy: 0.8718 - val_loss: 1.1453 - val_accuracy: 0.7800 - lr: 4.2079e-07\n",
      "Epoch 112/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1071 - accuracy: 0.8707\n",
      "Epoch 112: val_loss did not improve from 1.14462\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 2.1039400621702953e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1071 - accuracy: 0.8707 - val_loss: 1.1466 - val_accuracy: 0.7798 - lr: 4.2079e-07\n",
      "Epoch 113/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1028 - accuracy: 0.8720\n",
      "Epoch 113: val_loss did not improve from 1.14462\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1030 - accuracy: 0.8720 - val_loss: 1.1455 - val_accuracy: 0.7803 - lr: 2.1039e-07\n",
      "Epoch 114/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.0994 - accuracy: 0.8736\n",
      "Epoch 114: val_loss did not improve from 1.14462\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0998 - accuracy: 0.8735 - val_loss: 1.1460 - val_accuracy: 0.7791 - lr: 2.1039e-07\n",
      "Epoch 115/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1085 - accuracy: 0.8705\n",
      "Epoch 115: val_loss improved from 1.14462 to 1.14433, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1085 - accuracy: 0.8706 - val_loss: 1.1443 - val_accuracy: 0.7806 - lr: 2.1039e-07\n",
      "Epoch 116/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1031 - accuracy: 0.8717\n",
      "Epoch 116: val_loss did not improve from 1.14433\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1031 - accuracy: 0.8718 - val_loss: 1.1444 - val_accuracy: 0.7802 - lr: 2.1039e-07\n",
      "Epoch 117/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1025 - accuracy: 0.8733\n",
      "Epoch 117: val_loss did not improve from 1.14433\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1025 - accuracy: 0.8733 - val_loss: 1.1454 - val_accuracy: 0.7799 - lr: 2.1039e-07\n",
      "Epoch 118/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.0984 - accuracy: 0.8733\n",
      "Epoch 118: val_loss did not improve from 1.14433\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0984 - accuracy: 0.8733 - val_loss: 1.1448 - val_accuracy: 0.7808 - lr: 2.1039e-07\n",
      "Epoch 119/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1006 - accuracy: 0.8730\n",
      "Epoch 119: val_loss did not improve from 1.14433\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1009 - accuracy: 0.8729 - val_loss: 1.1449 - val_accuracy: 0.7796 - lr: 2.1039e-07\n",
      "Epoch 120/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1055 - accuracy: 0.8717\n",
      "Epoch 120: val_loss did not improve from 1.14433\n",
      "\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 1.0519700310851476e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1054 - accuracy: 0.8717 - val_loss: 1.1451 - val_accuracy: 0.7805 - lr: 2.1039e-07\n",
      "Epoch 121/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1049 - accuracy: 0.8721\n",
      "Epoch 121: val_loss did not improve from 1.14433\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1048 - accuracy: 0.8721 - val_loss: 1.1451 - val_accuracy: 0.7804 - lr: 1.0520e-07\n",
      "Epoch 122/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1015 - accuracy: 0.8722\n",
      "Epoch 122: val_loss improved from 1.14433 to 1.14428, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1015 - accuracy: 0.8722 - val_loss: 1.1443 - val_accuracy: 0.7805 - lr: 1.0520e-07\n",
      "Epoch 123/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1002 - accuracy: 0.8721\n",
      "Epoch 123: val_loss did not improve from 1.14428\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1004 - accuracy: 0.8720 - val_loss: 1.1444 - val_accuracy: 0.7803 - lr: 1.0520e-07\n",
      "Epoch 124/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1020 - accuracy: 0.8734\n",
      "Epoch 124: val_loss did not improve from 1.14428\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1020 - accuracy: 0.8734 - val_loss: 1.1447 - val_accuracy: 0.7801 - lr: 1.0520e-07\n",
      "Epoch 125/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1004 - accuracy: 0.8717\n",
      "Epoch 125: val_loss did not improve from 1.14428\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1004 - accuracy: 0.8717 - val_loss: 1.1445 - val_accuracy: 0.7803 - lr: 1.0520e-07\n",
      "Epoch 126/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1000 - accuracy: 0.8720\n",
      "Epoch 126: val_loss did not improve from 1.14428\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0999 - accuracy: 0.8720 - val_loss: 1.1443 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 127/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 1.1027 - accuracy: 0.8730\n",
      "Epoch 127: val_loss did not improve from 1.14428\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1027 - accuracy: 0.8730 - val_loss: 1.1449 - val_accuracy: 0.7803 - lr: 1.0000e-07\n",
      "Epoch 128/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1037 - accuracy: 0.8713\n",
      "Epoch 128: val_loss did not improve from 1.14428\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1037 - accuracy: 0.8712 - val_loss: 1.1445 - val_accuracy: 0.7802 - lr: 1.0000e-07\n",
      "Epoch 129/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1011 - accuracy: 0.8730\n",
      "Epoch 129: val_loss improved from 1.14428 to 1.14380, saving model to kfold_model/fold_5_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1010 - accuracy: 0.8730 - val_loss: 1.1438 - val_accuracy: 0.7803 - lr: 1.0000e-07\n",
      "Epoch 130/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1016 - accuracy: 0.8718\n",
      "Epoch 130: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1015 - accuracy: 0.8718 - val_loss: 1.1450 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 131/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.0998 - accuracy: 0.8735\n",
      "Epoch 131: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0998 - accuracy: 0.8735 - val_loss: 1.1451 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 132/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1003 - accuracy: 0.8737\n",
      "Epoch 132: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1003 - accuracy: 0.8737 - val_loss: 1.1446 - val_accuracy: 0.7796 - lr: 1.0000e-07\n",
      "Epoch 133/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1043 - accuracy: 0.8722\n",
      "Epoch 133: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1043 - accuracy: 0.8722 - val_loss: 1.1450 - val_accuracy: 0.7799 - lr: 1.0000e-07\n",
      "Epoch 134/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.0998 - accuracy: 0.8735\n",
      "Epoch 134: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0998 - accuracy: 0.8735 - val_loss: 1.1446 - val_accuracy: 0.7802 - lr: 1.0000e-07\n",
      "Epoch 135/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.0981 - accuracy: 0.8733\n",
      "Epoch 135: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0980 - accuracy: 0.8734 - val_loss: 1.1451 - val_accuracy: 0.7799 - lr: 1.0000e-07\n",
      "Epoch 136/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1000 - accuracy: 0.8732\n",
      "Epoch 136: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1000 - accuracy: 0.8732 - val_loss: 1.1448 - val_accuracy: 0.7799 - lr: 1.0000e-07\n",
      "Epoch 137/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1024 - accuracy: 0.8733\n",
      "Epoch 137: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1024 - accuracy: 0.8733 - val_loss: 1.1450 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 138/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1003 - accuracy: 0.8720\n",
      "Epoch 138: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1001 - accuracy: 0.8721 - val_loss: 1.1450 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 139/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1013 - accuracy: 0.8730\n",
      "Epoch 139: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1011 - accuracy: 0.8730 - val_loss: 1.1451 - val_accuracy: 0.7803 - lr: 1.0000e-07\n",
      "Epoch 140/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1023 - accuracy: 0.8737\n",
      "Epoch 140: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1022 - accuracy: 0.8737 - val_loss: 1.1448 - val_accuracy: 0.7795 - lr: 1.0000e-07\n",
      "Epoch 141/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.8721\n",
      "Epoch 141: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1035 - accuracy: 0.8721 - val_loss: 1.1455 - val_accuracy: 0.7797 - lr: 1.0000e-07\n",
      "Epoch 142/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.0987 - accuracy: 0.8727\n",
      "Epoch 142: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0989 - accuracy: 0.8727 - val_loss: 1.1444 - val_accuracy: 0.7802 - lr: 1.0000e-07\n",
      "Epoch 143/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1028 - accuracy: 0.8706\n",
      "Epoch 143: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1027 - accuracy: 0.8706 - val_loss: 1.1445 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 144/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1002 - accuracy: 0.8734\n",
      "Epoch 144: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1004 - accuracy: 0.8732 - val_loss: 1.1444 - val_accuracy: 0.7802 - lr: 1.0000e-07\n",
      "Epoch 145/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1011 - accuracy: 0.8720\n",
      "Epoch 145: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1010 - accuracy: 0.8720 - val_loss: 1.1446 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 146/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1025 - accuracy: 0.8720\n",
      "Epoch 146: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1025 - accuracy: 0.8720 - val_loss: 1.1445 - val_accuracy: 0.7802 - lr: 1.0000e-07\n",
      "Epoch 147/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.0979 - accuracy: 0.8729\n",
      "Epoch 147: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0976 - accuracy: 0.8729 - val_loss: 1.1440 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 148/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.0997 - accuracy: 0.8734\n",
      "Epoch 148: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0996 - accuracy: 0.8734 - val_loss: 1.1447 - val_accuracy: 0.7798 - lr: 1.0000e-07\n",
      "Epoch 149/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1030 - accuracy: 0.8722\n",
      "Epoch 149: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1030 - accuracy: 0.8722 - val_loss: 1.1445 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 150/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.0995 - accuracy: 0.8725\n",
      "Epoch 150: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0994 - accuracy: 0.8724 - val_loss: 1.1447 - val_accuracy: 0.7796 - lr: 1.0000e-07\n",
      "Epoch 151/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1019 - accuracy: 0.8735\n",
      "Epoch 151: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1018 - accuracy: 0.8735 - val_loss: 1.1446 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 152/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.1010 - accuracy: 0.8740\n",
      "Epoch 152: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1009 - accuracy: 0.8740 - val_loss: 1.1444 - val_accuracy: 0.7798 - lr: 1.0000e-07\n",
      "Epoch 153/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1009 - accuracy: 0.8733\n",
      "Epoch 153: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1010 - accuracy: 0.8733 - val_loss: 1.1445 - val_accuracy: 0.7809 - lr: 1.0000e-07\n",
      "Epoch 154/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.1020 - accuracy: 0.8723\n",
      "Epoch 154: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1022 - accuracy: 0.8722 - val_loss: 1.1443 - val_accuracy: 0.7802 - lr: 1.0000e-07\n",
      "Epoch 155/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.1017 - accuracy: 0.8734\n",
      "Epoch 155: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1015 - accuracy: 0.8735 - val_loss: 1.1451 - val_accuracy: 0.7795 - lr: 1.0000e-07\n",
      "Epoch 156/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1006 - accuracy: 0.8726\n",
      "Epoch 156: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1006 - accuracy: 0.8726 - val_loss: 1.1445 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 157/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.1000 - accuracy: 0.8721\n",
      "Epoch 157: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0999 - accuracy: 0.8721 - val_loss: 1.1446 - val_accuracy: 0.7794 - lr: 1.0000e-07\n",
      "Epoch 158/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.0985 - accuracy: 0.8722\n",
      "Epoch 158: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0987 - accuracy: 0.8722 - val_loss: 1.1446 - val_accuracy: 0.7803 - lr: 1.0000e-07\n",
      "Epoch 159/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1011 - accuracy: 0.8722\n",
      "Epoch 159: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1011 - accuracy: 0.8722 - val_loss: 1.1443 - val_accuracy: 0.7797 - lr: 1.0000e-07\n",
      "Epoch 160/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.1003 - accuracy: 0.8723\n",
      "Epoch 160: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1002 - accuracy: 0.8723 - val_loss: 1.1451 - val_accuracy: 0.7799 - lr: 1.0000e-07\n",
      "Epoch 161/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 1.0989 - accuracy: 0.8726\n",
      "Epoch 161: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0991 - accuracy: 0.8725 - val_loss: 1.1450 - val_accuracy: 0.7801 - lr: 1.0000e-07\n",
      "Epoch 162/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.0991 - accuracy: 0.8733\n",
      "Epoch 162: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0992 - accuracy: 0.8733 - val_loss: 1.1444 - val_accuracy: 0.7803 - lr: 1.0000e-07\n",
      "Epoch 163/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 1.0962 - accuracy: 0.8729\n",
      "Epoch 163: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0961 - accuracy: 0.8730 - val_loss: 1.1440 - val_accuracy: 0.7799 - lr: 1.0000e-07\n",
      "Epoch 164/210\n",
      "2822/2830 [============================>.] - ETA: 0s - loss: 1.1008 - accuracy: 0.8720\n",
      "Epoch 164: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1010 - accuracy: 0.8719 - val_loss: 1.1441 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 165/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 1.0989 - accuracy: 0.8733\n",
      "Epoch 165: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0988 - accuracy: 0.8733 - val_loss: 1.1440 - val_accuracy: 0.7799 - lr: 1.0000e-07\n",
      "Epoch 166/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 1.0986 - accuracy: 0.8725\n",
      "Epoch 166: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0986 - accuracy: 0.8725 - val_loss: 1.1445 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 167/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 1.0992 - accuracy: 0.8719\n",
      "Epoch 167: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.0991 - accuracy: 0.8719 - val_loss: 1.1446 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 168/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 1.1011 - accuracy: 0.8723\n",
      "Epoch 168: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1009 - accuracy: 0.8723 - val_loss: 1.1446 - val_accuracy: 0.7798 - lr: 1.0000e-07\n",
      "Epoch 169/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 1.1004 - accuracy: 0.8721\n",
      "Epoch 169: val_loss did not improve from 1.14380\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 1.1004 - accuracy: 0.8721 - val_loss: 1.1450 - val_accuracy: 0.7800 - lr: 1.0000e-07\n",
      "Epoch 169: early stopping\n",
      "Training fold 6...\n",
      "Epoch 1/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 16.7467 - accuracy: 0.3618\n",
      "Epoch 1: val_loss improved from inf to 11.77165, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 23s 7ms/step - loss: 16.7467 - accuracy: 0.3618 - val_loss: 11.7717 - val_accuracy: 0.4485 - lr: 2.1544e-04\n",
      "Epoch 2/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 10.9185 - accuracy: 0.5108\n",
      "Epoch 2: val_loss improved from 11.77165 to 7.62311, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 10.9182 - accuracy: 0.5108 - val_loss: 7.6231 - val_accuracy: 0.5981 - lr: 2.1544e-04\n",
      "Epoch 3/210\n",
      "2825/2830 [============================>.] - ETA: 0s - loss: 7.6577 - accuracy: 0.5814\n",
      "Epoch 3: val_loss improved from 7.62311 to 5.96992, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 7.6570 - accuracy: 0.5814 - val_loss: 5.9699 - val_accuracy: 0.5797 - lr: 2.1544e-04\n",
      "Epoch 4/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 6.0593 - accuracy: 0.6083\n",
      "Epoch 4: val_loss improved from 5.96992 to 4.32505, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 6.0590 - accuracy: 0.6082 - val_loss: 4.3250 - val_accuracy: 0.6456 - lr: 2.1544e-04\n",
      "Epoch 5/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 5.0553 - accuracy: 0.6280\n",
      "Epoch 5: val_loss improved from 4.32505 to 3.80291, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 5.0552 - accuracy: 0.6279 - val_loss: 3.8029 - val_accuracy: 0.6310 - lr: 2.1544e-04\n",
      "Epoch 6/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 4.4621 - accuracy: 0.6412\n",
      "Epoch 6: val_loss improved from 3.80291 to 3.31228, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 4.4620 - accuracy: 0.6412 - val_loss: 3.3123 - val_accuracy: 0.6643 - lr: 2.1544e-04\n",
      "Epoch 7/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 4.1546 - accuracy: 0.6445\n",
      "Epoch 7: val_loss did not improve from 3.31228\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 4.1546 - accuracy: 0.6445 - val_loss: 3.3410 - val_accuracy: 0.6071 - lr: 2.1544e-04\n",
      "Epoch 8/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 3.9147 - accuracy: 0.6503\n",
      "Epoch 8: val_loss improved from 3.31228 to 2.82427, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.9145 - accuracy: 0.6504 - val_loss: 2.8243 - val_accuracy: 0.6791 - lr: 2.1544e-04\n",
      "Epoch 9/210\n",
      "2829/2830 [============================>.] - ETA: 0s - loss: 3.6265 - accuracy: 0.6613\n",
      "Epoch 9: val_loss did not improve from 2.82427\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.6264 - accuracy: 0.6613 - val_loss: 2.8571 - val_accuracy: 0.6554 - lr: 2.1544e-04\n",
      "Epoch 10/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 3.4966 - accuracy: 0.6654\n",
      "Epoch 10: val_loss improved from 2.82427 to 2.43984, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.4963 - accuracy: 0.6654 - val_loss: 2.4398 - val_accuracy: 0.7031 - lr: 2.1544e-04\n",
      "Epoch 11/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 3.4702 - accuracy: 0.6620\n",
      "Epoch 11: val_loss did not improve from 2.43984\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.4701 - accuracy: 0.6620 - val_loss: 2.6307 - val_accuracy: 0.6682 - lr: 2.1544e-04\n",
      "Epoch 12/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 3.3550 - accuracy: 0.6678\n",
      "Epoch 12: val_loss did not improve from 2.43984\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.3550 - accuracy: 0.6678 - val_loss: 2.4976 - val_accuracy: 0.6921 - lr: 2.1544e-04\n",
      "Epoch 13/210\n",
      "2826/2830 [============================>.] - ETA: 0s - loss: 3.2309 - accuracy: 0.6710\n",
      "Epoch 13: val_loss improved from 2.43984 to 2.35920, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.2307 - accuracy: 0.6710 - val_loss: 2.3592 - val_accuracy: 0.6833 - lr: 2.1544e-04\n",
      "Epoch 14/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 3.0725 - accuracy: 0.6763\n",
      "Epoch 14: val_loss did not improve from 2.35920\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0724 - accuracy: 0.6762 - val_loss: 2.5300 - val_accuracy: 0.6671 - lr: 2.1544e-04\n",
      "Epoch 15/210\n",
      "2824/2830 [============================>.] - ETA: 0s - loss: 3.0729 - accuracy: 0.6791\n",
      "Epoch 15: val_loss did not improve from 2.35920\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0727 - accuracy: 0.6790 - val_loss: 2.3996 - val_accuracy: 0.6732 - lr: 2.1544e-04\n",
      "Epoch 16/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 3.0979 - accuracy: 0.6781\n",
      "Epoch 16: val_loss improved from 2.35920 to 2.12140, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.0978 - accuracy: 0.6781 - val_loss: 2.1214 - val_accuracy: 0.7057 - lr: 2.1544e-04\n",
      "Epoch 17/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.9676 - accuracy: 0.6827\n",
      "Epoch 17: val_loss did not improve from 2.12140\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.9676 - accuracy: 0.6827 - val_loss: 2.4232 - val_accuracy: 0.6573 - lr: 2.1544e-04\n",
      "Epoch 18/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 3.1008 - accuracy: 0.6755\n",
      "Epoch 18: val_loss did not improve from 2.12140\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 3.1007 - accuracy: 0.6754 - val_loss: 2.1777 - val_accuracy: 0.6960 - lr: 2.1544e-04\n",
      "Epoch 19/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.9174 - accuracy: 0.6847\n",
      "Epoch 19: val_loss did not improve from 2.12140\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.9174 - accuracy: 0.6847 - val_loss: 2.7440 - val_accuracy: 0.5887 - lr: 2.1544e-04\n",
      "Epoch 20/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.8354 - accuracy: 0.6889\n",
      "Epoch 20: val_loss improved from 2.12140 to 1.82919, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8354 - accuracy: 0.6889 - val_loss: 1.8292 - val_accuracy: 0.7175 - lr: 2.1544e-04\n",
      "Epoch 21/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.8848 - accuracy: 0.6805\n",
      "Epoch 21: val_loss did not improve from 1.82919\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8848 - accuracy: 0.6805 - val_loss: 2.3948 - val_accuracy: 0.6572 - lr: 2.1544e-04\n",
      "Epoch 22/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.7956 - accuracy: 0.6911\n",
      "Epoch 22: val_loss did not improve from 1.82919\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7955 - accuracy: 0.6910 - val_loss: 1.8981 - val_accuracy: 0.7125 - lr: 2.1544e-04\n",
      "Epoch 23/210\n",
      "2823/2830 [============================>.] - ETA: 0s - loss: 2.8399 - accuracy: 0.6846\n",
      "Epoch 23: val_loss did not improve from 1.82919\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.8397 - accuracy: 0.6847 - val_loss: 2.1666 - val_accuracy: 0.7064 - lr: 2.1544e-04\n",
      "Epoch 24/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.6875 - accuracy: 0.6945\n",
      "Epoch 24: val_loss did not improve from 1.82919\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.6877 - accuracy: 0.6944 - val_loss: 2.0940 - val_accuracy: 0.6839 - lr: 2.1544e-04\n",
      "Epoch 25/210\n",
      "2830/2830 [==============================] - ETA: 0s - loss: 2.7170 - accuracy: 0.6933\n",
      "Epoch 25: val_loss did not improve from 1.82919\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010772173118311912.\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.7170 - accuracy: 0.6933 - val_loss: 1.9136 - val_accuracy: 0.6911 - lr: 2.1544e-04\n",
      "Epoch 26/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.3280 - accuracy: 0.7222\n",
      "Epoch 26: val_loss improved from 1.82919 to 1.67985, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.3279 - accuracy: 0.7222 - val_loss: 1.6799 - val_accuracy: 0.7221 - lr: 1.0772e-04\n",
      "Epoch 27/210\n",
      "2828/2830 [============================>.] - ETA: 0s - loss: 2.2549 - accuracy: 0.7247\n",
      "Epoch 27: val_loss improved from 1.67985 to 1.56638, saving model to kfold_model/fold_6_b30_e210_model.keras\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.2549 - accuracy: 0.7247 - val_loss: 1.5664 - val_accuracy: 0.7382 - lr: 1.0772e-04\n",
      "Epoch 28/210\n",
      "2827/2830 [============================>.] - ETA: 0s - loss: 2.2398 - accuracy: 0.7268\n",
      "Epoch 28: val_loss did not improve from 1.56638\n",
      "2830/2830 [==============================] - 19s 7ms/step - loss: 2.2397 - accuracy: 0.7268 - val_loss: 1.8360 - val_accuracy: 0.6632 - lr: 1.0772e-04\n",
      "Epoch 29/210\n",
      "2794/2830 [============================>.] - ETA: 0s - loss: 2.1793 - accuracy: 0.7325"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 43\u001b[0m\n\u001b[1;32m     34\u001b[0m mc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkfold_model/fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_b\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Increment fold counter\u001b[39;00m\n\u001b[1;32m     55\u001b[0m fold_no \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "batch = 30\n",
    "epoch = 210\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "\n",
    "# Prepare for tracking results\n",
    "fold_no = 4\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    print(f\"Training fold {fold_no}...\")\n",
    "    \n",
    "    dropout = 0.5\n",
    "    model = network_new((nbins, 1), ncat=y.shape[1], dropout = dropout)\n",
    "\n",
    "    # Split the data into train and test for this fold\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Define callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40)\n",
    "    mc = ModelCheckpoint(\n",
    "        f'kfold_model/fold_{fold_no}_b{batch}_e{epoch}_model.keras',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    hist = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch,\n",
    "        epochs=epoch,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True,\n",
    "        verbose=True,\n",
    "        callbacks=[es, mc, reduce_lr],\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "\n",
    "    # Increment fold counter\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047f32f-13d5-476d-af79-63864a11e60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.15.0",
   "language": "python",
   "name": "tensorflow-2.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
